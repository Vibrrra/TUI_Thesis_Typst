%% This BibTeX bibliography file was created using BibDesk.
%% http://bibdesk.sourceforge.net/

%% Created by Vesa Valimaki and Kurt James Werner 2021-03-01 13:12:01 +0200 

%% Saved with string encoding Unicode (UTF-8) 

For more than 6 authors, please truncate the list after 6 author names by inserting "and others", which will show as "et al." in References. When there are fewer than seven authors, please list all author names in full.

An article in a journal. Note the use of official abbreviation for the journal name. The first letter of all main words in the title must be capitalized. Use a three-letter abbreviation for the month (Jan./Feb./Mar./Apr./May/Jun./Jul./Aug./Sep./Oct./Nov./Dec.).

@inproceedings{wirler2020towards,
  title={Towards transfer-plausibility for evaluating mixed reality audio in complex scenes},
  author={Wirler, S. A. and Meyer-Kahlen, N. and Schlecht, S. J.},
  booktitle={Audio Engineering Society Conference: 2020 AES International Conference on Audio for Virtual and Augmented Reality},
  year={2020},
  organization={Audio Engineering Society}
}

@inproceedings{Meng2006,
  title={The just noticeable difference of noise length and reverberation perception},
  author={Meng, Z. and Zhao, F. and He, M.},
  booktitle={2006 International Symposium on Communications and Information Technologies},
  pages={418--421},
  year={2006},
  organization={IEEE}
}
@inproceedings{Blevins2013,
author = {Blevins, M. G and Buck, A. and Peng, Z. E. and Wang, L.},
year = {2013},
month = {06},
pages = {},
title = {Quantifying the just noticeable difference of reverberation time with band-limited noise centered around 1000 Hz using a transformed up-down adaptive method},
booktitle={International Symposium on Room Acoustics}
}
@inproceedings{Karjalainen2001,
    author = {Karjalainen, M. and Jarvelainen, H.} ,
    title = {More about this reverberation science: Perceptually good late reverberation},
    booktitle = {111th Convention of the Audio Engineering Society },
    year ={2001} 
}

@article{seraphim1958,
  title={Untersuchungen {\"u}ber die Unterschiedsschwelle exponentiellen Abklingens von Rauschbandimpulsen},
  author={Seraphim, H.-P.},
  journal={Acta Acustica united with Acustica},
  volume={8},
  number={4},
  pages={280--284},
  year={1958},
  publisher={European Acoustics Association}
}

@inproceedings{Frissen2009,
  title={Effect of sound source stimuli on the perception of reverberation in large volumes},
  author={Frissen, I. and Katz, B. FG and Guastavino, C.},
  booktitle={International Symposium on Computer Music Modeling and Retrieval},
  pages={358--376},
  year={2009},
  organization={Springer}
}


@article{Hodgson2002,
    author = {Hodgson, M. and Nosal, E.-M.},
    title = {Effect of noise and occupancy on optimal reverberation times for speech intelligibility in classrooms},
    journal = {The Journal of the Acoustical Society of America},
    volume = {111},
    number = {2},
    pages = {931-939},
    year = {2002},
    month = {02},
    abstract = {The question of what is the optimal reverberation time for speech intelligibility in an occupied classroom has been studied recently in two different ways, with contradictory results. Experiments have been performed under various conditions of speech-signal to background-noise level difference and reverberation time, finding an optimal reverberation time of zero. Theoretical predictions of appropriate speech-intelligibility metrics, based on diffuse-field theory, found nonzero optimal reverberation times. These two contradictory results are explained by the different ways in which the two methods account for background noise, both of which are unrealistic. To obtain more realistic and accurate predictions, noise sources inside the classroom are considered. A more realistic treatment of noise is incorporated into diffuse-field theory by considering both speech and noise sources and the effects of reverberation on their steady-state levels. The model shows that the optimal reverberation time is zero when the speech source is closer to the listener than the noise source, and nonzero when the noise source is closer than the speech source. Diffuse-field theory is used to determine optimal reverberation times in unoccupied classrooms given optimal values for the occupied classroom. Resulting times can be as high as several seconds in large classrooms; in some cases, optimal values are unachievable, because the occupants contribute too much absorption.},
    issn = {0001-4966},
    doi = {10.1121/1.1428264},
    url = {https://doi.org/10.1121/1.1428264},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/111/2/931/8089600/931\_1\_online.pdf},
}





@article{Martellotta2010,
    author = {Martellotta, F.},
    title = {The just noticeable difference of center time and clarity index in large reverberant spaces},
    journal = {The Journal of the Acoustical Society of America},
    volume = {128},
    number = {2},
    pages = {654-663},
    year = {2010},
    month = {08},
    abstract = {Just noticeable difference (JND) values are available for most acoustical parameters currently used in practice. However, they have been determined with reference to conditions typically encountered in concert halls and in rooms for speech, covering a range of reverberation times (T) spanning from 0.5 s to 2 s. When reverberation gets longer, the relationship between measured parameters describing acoustic clarity may change significantly and subjective perception might also be different. The proposed research investigates the influence of reverberation time on JND for clarity measures taking into account three reference cases having T values varying from 2 s to 6 s. Measured B-format impulse responses were properly modified to introduce the desired changes and then auralized with two music motifs for presentation on a 4-channel playback system. Listening tests based on paired comparisons were carried out to determine subjective limens. The results proved to be independent of music motifs and showed that JND in the clarity index is almost independent of T, while JND in the center time is significantly related to T and can be assumed as the 8.5\% of the reference TS value.},
    issn = {0001-4966},
    doi = {10.1121/1.3455837},
    url = {https://doi.org/10.1121/1.3455837},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/128/2/654/14110829/654\_1\_online.pdf},
}





@PhdThesis{AnnikaPhD,
  author = 	{Neidhardt, A.},
  title = 	{On the plausibility of simplified acoustic room representations for listener translation in dynamic binaural auralizations},
  year = 	{2023},
  month = 	{Oct},
  day = 	{05},
  address = 	{Ilmenau},
school = {Technische Universit{\"a}t Ilmenau},
  keywords = 	{Binaurales H{\"o}ren; Wiedergabetechnik; Virtuelle Realit{\"a}t; Erweiterte Realit{\"a}t <Informatik>; Mixed Reality},
  abstract = 	{Diese Doktorarbeit untersucht die Wahrnehmung vereinfachter akustischer Raumrepr{\"a}sentationen in positionsdynamischer Binauralwiedergabe f{\"u}r die H{\"o}rertranslation. Die dynamische Binauralsynthese ist eine Audiowiedergabemethode zur Erzeugung r{\"a}umlicher auditiver Illusionen {\"u}ber Kopfh{\"o}rer f{\"u}r virtuelle, erweiterte und gemischte Realit{\"a}t (VR/AR/MR). Dabei ist es nun eine typische Anforderung, immersive Inhalte in sechs Freiheitsgraden (6DOF) zu erkunden. Dynamische binaurale Schallfeldimitationen mit hoher physikalischer Genauigkeit zu realisieren, ist meist mit sehr hohem Rechenaufwand verbunden. Fr{\"u}here psychoakustische Studien weisen jedoch darauf hin, dass Menschen eine begrenzte Empfindlichkeit gegen{\"u}ber den Details des Schallfelds haben, insbesondere im sp{\"a}ten Nachhall. Dies birgt das Potential physikalischer Vereinfachungen bei der positionsdynamischen Auralisation von R{\"a}umen. Beispielsweise wurden Konzepte vorgeschlagen, die auf der perzeptiven Mixing Time oder der H{\"o}rbarkeitsschwelle von fr{\"u}hen Reflexionen basieren, f{\"u}r welche jedoch eine gr{\"u}ndliche psychoakustische Bewertung noch aussteht. Zun{\"a}chst wurde ein Aufbau zur positionsdynamischen Raumauralisation implementiert und evaluiert. Daran untersucht die Arbeit wesentliche Systemparameter wie die erforderliche r{\"a}umliche Aufl{\"o}sung eines Positionsrasters f{\"u}r die dynamische Anpassung. Da allgemein etablierte Testmethoden zur wahrnehmungsbezogenen Bewertung von r{\"a}umlichen auditiven Illusionen unter Ber{\"u}cksichtigung interaktiver H{\"o}rertranslation fehlten, untersucht die Arbeit verschiedene Ans{\"a}tze zur Messung der Plausibilit{\"a}t. Auf dieser Grundlage werden physikalische Vereinfachungen im Verlauf des Schallfeldes in positionsdynamischen binauralen Auralisationen der Raumakustik untersucht. F{\"u}r die Hauptexperimente wurden binaurale Raumimpulsantworten (BRIRs) entlang einer Linie f{\"u}r die H{\"o}rertranslation in einem eher trockenen H{\"o}rlabor und einem halligen Seminarraum {\"a}hnlicher Gr{\"o}{\ss}e gemessen. Die erstellten Datens{\"a}tze enthalten Szenarien von H{\"o}rerbewegungen auf eine virtuelle Schallquelle zu, daran vorbei, davon weg oder dahinter. Dar{\"u}ber hinaus betrachten die Untersuchungen zwei Extremf{\"a}lle der Quellenorientierung, um die Auswirkungen einer Variation der Schallquellenrichtcharakteristik zu ber{\"u}cksichtigen. Die BRIR-S{\"a}tze werden systematisch bearbeitet und vereinfacht, um die Auswirkungen auf die Wahrnehmung zu bewerten. Insbesondere das Konzept der perzeptiven Mixing Time und manipulierte r{\"a}umlich-zeitliche Muster fr{\"u}her Reflexionen dienten als Testf{\"a}lle in den psychoakustischen Studien. Die Ergebnisse zeigen ein hohes Potential f{\"u}r Vereinfachungen, unterstreichen aber auch die Relevanz der genauen Imitation prominenter fr{\"u}her Reflexionen. Die Ergebnisse best{\"a}tigen auch das Konzept der wahrnehmungsbezogenen Mixing Time f{\"u}r die betrachteten F{\"a}lle der positionsdynamischen binauralen Wiedergabe. Die Beobachtungen verdeutlichen, dass g{\"a}ngige Testszenarien f{\"u}r Auralisierungen, Interpolation und Extrapolation nicht kritisch genug sind, um allgemeine Schlussfolgerungen {\"u}ber die Eignung der getesteten Rendering-Ans{\"a}tze zu ziehen. Die Arbeit zeigt L{\"o}sungsans{\"a}tze auf.},
  doi = 	{10.22032/dbt.57596},
  url = 	{https://www.db-thueringen.de/receive/dbt_mods_00057596},
  url = 	{http://uri.gbv.de/document/gvk:ppn:1860745229},
  url = 	{https://doi.org/10.22032/dbt.57596},
  file = 	{:https://www.db-thueringen.de/servlets/MCRFileNodeServlet/dbt_derivate_00061447/ilm1-2023000155.pdf:PDF},
  language = 	{en}
}

@inproceedings{beyondlooks,
author = { Arboleda, S. A. and Kunert, C. and Hartbrich, J. and Schneiderwind, C. and Diao, C. and Gerhardt, C. and Surdu, T. and Weidner, F. and Broll, W. and Werner, S. and Raake, A. },
booktitle = { 2024 IEEE Conference Virtual Reality and 3D User Interfaces (VR) },
title = {{ Beyond Looks: A Study on Agent Movement and Audiovisual Spatial Coherence in Augmented Reality }},
year = {2024},
volume = {},
ISSN = {},
pages = {502-512},
abstract = { The appearance of virtual humans (avatars and agents) has been widely explored in immersive environments. However, virtual humans’ movements and associated sounds in real-world interactions, particularly in Augmented Reality (AR), are yet to be explored. In this paper, we investigate the influence of three distinct movement patterns (circle, side-to-side, and standing), two rendering styles (realistic and cartoon), and two types of audio (spatial audio and non-spatial audio) on emotional responses, social presence, appearance and behavior plausibility, audiovisual coherence, and auditory plausibility. To enable that, we conducted a study (N=36) where participants observed an agent reciting a short fictional story. Our results indicate an effect of the rendering style and the type of movement on the subjective perception of the agents behaving in an AR environment. Participants reported higher levels of excitement when they observed the realistic agent moving in a circle compared to the cartoon agent or the other two movement patterns. Moreover, we found an influence of agent’s movement pattern on social presence and higher appearance and behavior plausibility for the realistic rendering style. Regarding audiovisual spatial coherence, we found an influence of rendering style and type of audio only for the cartoon agent. Additionally, the spatial audio was perceived as more plausible than non-spatial audio. Our findings suggest that aligning realistic rendering styles with realistic auditory experiences may not be necessary for 1-1 listening experiences with moving sources. However, movement patterns of agents influence excitement and social presence in passive unidirectional communication scenarios. },
keywords = {Visualization;Spatial audio;Spatial coherence;Coherence;Tutorials;User interfaces;Rendering (computer graphics)},
doi = {10.1109/VR58804.2024.00071},
url = {https://doi.ieeecomputersociety.org/10.1109/VR58804.2024.00071},
publisher = {IEEE Computer Society},
address = {Los Alamitos, CA, USA},
month =mar
}

@INPROCEEDINGS{Nieuwenhuijse1998,
  author={Nieuwenhuijse, J. and Heusens, R. and Deprettere, Ed.F.},
  booktitle={Proceedings of the 1998 IEEE International Conference on Acoustics, Speech and Signal Processing, ICASSP '98 (Cat. No.98CH36181)}, 
  title={Robust exponential modeling of audio signals}, 
  year={1998},
  volume={6},
  number={},
  pages={3581-3584 vol.6},
  keywords={Robustness;Bit rate;Audio coding;Speech;Signal analysis;Standardization;Damping;Data models;Signal to noise ratio;Qualifications},
  doi={10.1109/ICASSP.1998.679650}}

@article{Brimijoin2013,
    doi = {10.1371/journal.pone.0083068},
    author = {Brimijoin, W. Owen AND Boyd, Alan W. AND Akeroyd, Michael A.},
    journal = {PLOS ONE},
    publisher = {Public Library of Science},
    title = {The Contribution of Head Movement to the Externalization and Internalization of Sounds},
    year = {2013},
    month = {12},
    volume = {8},
    url = {https://doi.org/10.1371/journal.pone.0083068},
    pages = {null},
    abstract = {BackgroundWhen stimuli are presented over headphones, they are typically perceived as internalized; i.e., they appear to emanate from inside the head. Sounds presented in the free-field tend to be externalized, i.e., perceived to be emanating from a source in the world. This phenomenon is frequently attributed to reverberation and to the spectral characteristics of the sounds: those sounds whose spectrum and reverberation matches that of free-field signals arriving at the ear canal tend to be more frequently externalized. Another factor, however, is that the virtual location of signals presented over headphones moves in perfect concert with any movements of the head, whereas the location of free-field signals moves in opposition to head movements. The effects of head movement have not been systematically disentangled from reverberation and/or spectral cues, so we measured the degree to which movements contribute to externalization.   Methodology/Principal FindingsWe performed two experiments: 1) Using motion tracking and free-field loudspeaker presentation, we presented signals that moved in their spatial location to match listeners’ head movements. 2) Using motion tracking and binaural room impulse responses, we presented filtered signals over headphones that appeared to remain static relative to the world. The results from experiment 1 showed that free-field signals from the front that move with the head are less likely to be externalized (23%) than those that remain fixed (63%). Experiment 2 showed that virtual signals whose position was fixed relative to the world are more likely to be externalized (65%) than those fixed relative to the head (20%), regardless of the fidelity of the individual impulse responses.   Conclusions/SignificanceHead movements play a significant role in the externalization of sound sources. These findings imply tight integration between binaural cues and self motion cues and underscore the importance of self motion for spatial auditory perception.},
    number = {12},

}

@article{epub115254,
       publisher = {AIP Publishing},
           title = {Auditory orientation and distance estimation of sighted humans using virtual echolocation with artificial and self-generated sounds},
          author = {H. Steffens and M. Schutte and S. D. Ewert},
        abstract = {Active echolocation of sighted humans using predefined synthetic and self-emitted sounds, as habitually used by blind individuals, was investigated. Using virtual acoustics, distance estimation and directional localization of a wall in different rooms were assessed. A virtual source was attached to either the head or hand with realistic or increased source directivity. A control condition was tested with a virtual sound source located at the wall. Untrained echolocation performance comparable to performance in the control condition was achieved on an individual level. On average, the echolocation performance was considerably lower than in the control condition, however, it benefitted from increased directivity. (C) 2022 Author(s).},
          number = {12},
            year = {2022},
         journal = {Jasa Express Letters},
             url = {}
}


@article{gupta2022augmented,
  title={Augmented/mixed reality audio for hearables: Sensing, control, and rendering},
  author={Gupta, R. and He, J. and Ranjan, R. and Gan, WS. and Klein, F. and Schneiderwind, C. and Neidhardt, A. and Brandenburg, K. and V{\"a}lim{\"a}ki, V.},
  journal={IEEE Signal Processing Magazine},
  volume={39},
  number={3},
  pages={63--89},
  year={2022},
  publisher={IEEE}
}

@INPROCEEDINGS{WangBlindEst2025,
  author={Wang, C. and Jia, M. and Li, M. and Bao, C. and Jin, W.},
  booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  title={SS-BRPE: Self-Supervised Blind Room Parameter Estimation Using Attention Mechanisms}, 
  year={2025},
  volume={},
  number={},
  pages={1-5},
  keywords={Training;Adaptation models;Parameter estimation;Attention mechanisms;Accuracy;Transfer learning;Self-supervised learning;Signal processing;Reverberation;Speech processing},
  doi={10.1109/ICASSP49660.2025.10890462}}


@article{Leclere2019,
    author = {Leclère, T. and Lavandier, M. and Perrin, F.},
    title = {On the externalization of sound sources with headphones without reference to a real source},
    journal = {The Journal of the Acoustical Society of America},
    volume = {146},
    number = {4},
    pages = {2309-2320},
    year = {2019},
    month = {10},
    abstract = {Sounds presented over headphones are generally perceived as internalized, i.e., originating from a source inside the head. Prior filtering by binaural room impulse responses (BRIRs) can create externalized sources. Previous studies concluded that these BRIRs need to be listener-specific to produce good externalization; however, listeners were generally facing a loudspeaker and asked to rate externalization relative to that loudspeaker, meaning that the source had to be perceived outside the head and also at the right distance. The present study investigated externalization when there is no visual source to match. Overall, lateral sources were perceived as more externalized than frontal sources. Experiment 1 showed that the perceived externalization obtained with non-individualized BRIRs measured in three different rooms was similar to that obtained with a state-of-the-art simulation using individualized BRIRs. Experiment 2 indicated that when there is no real source spectrum to match, headphone equalization does not improve externalization. Experiment 3 further showed that reverberation improved externalization only when it introduced interaural differences. Correlation analyses finally showed a close correspondence between perceived externalization and binaural cues (especially interaural coherence).},
    issn = {0001-4966},
    doi = {10.1121/1.5128325},
    url = {https://doi.org/10.1121/1.5128325},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/146/4/2309/15338294/2309\_1\_online.pdf},
}




@article{Best2020SoundEA,
  title={Sound Externalization: A Review of Recent Research},
  author={V. Best and R. Baumgartner and M. Lavandier and P. Majdak and N. Kopčo},
  journal={Trends in Hearing},
  year={2020},
  volume={24},
  url={https://api.semanticscholar.org/CorpusID:221621478}
}
@INPROCEEDINGS{Steinmetz2024,
  author={Steinmetz, C. J. and Ithapu, V. K. and Calamia, P.},
  booktitle={2021 IEEE Workshop on Applications of Signal Processing to Audio and Acoustics (WASPAA)}, 
  title={Filtered Noise Shaping for Time Domain Room Impulse Response Estimation from Reverberant Speech}, 
  year={2021},
  volume={},
  number={},
  pages={221-225},
  keywords={Matched filters;Estimation;Transforms;Predictive models;Filtering algorithms;Acoustics;Reflection;Room impulse response;acoustic matching;reverberation;synthesis;blind estimation},
  doi={10.1109/WASPAA52581.2021.9632680}}

@ARTICLE{Deppisch2024,
  author={Deppisch, T. and Meyer-Kahlen, N. and Garí, S. V. A.},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing}, 
  title={Blind Identification of Binaural Room Impulse Responses From Smart Glasses}, 
  year={2024},
  volume={32},
  number={},
  pages={4052-4065},
  keywords={Estimation;Rendering (computer graphics);Noise;Array signal processing;Microphone arrays;Acoustic measurements;Smart glasses;Augmented reality;binaural room impulse response;blind system identification;microphone array;smart glasses},
  doi={10.1109/TASLP.2024.3454964}}

@dataset{neidhardt_2020_3457782,
  author       = {Neidhardt, A. and
                  Zerlik, A.-M. and
                  Kamandi, Samaneh},
  title        = {BRIR data set for interactive listener translation
                   in two rooms
                  },
  month        = jul,
  year         = 2020,
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.3457782},
  url          = {https://doi.org/10.5281/zenodo.3457782},
}

@article{Arend2021c,
author = {Arend, J. M. and {A. Gar{\'{i}}}, S. V. and Schissler, C. and Klein, F. and Robinson, P. W.},
doi = {https://doi.org/10.17743/jaes.2021.0009},
journal = {J. Audio Eng. Soc.},
number = {7/8},
pages = {557--575},
title = {{Six-Degrees-of-Freedom Parametric Spatial Audio Based on One Monaural Room Impulse Response}},
volume = {69},
year = {2021}
}

@inproceedings{Prschmann2017BINAURALIZATIONOO,
  title={BINAURALIZATION OF OMNIDIRECTIONAL ROOM IMPULSE RESPONSES-ALGORITHM AND TECHNICAL EVALUATION},
  author={C. P{\"o}rschmann and P. Stade and J. M. Arend},
  booktitle={Proceedings of the 20th International Conference on Digital Audio Effects (DAFx-17), Edinburgh, UK, September 5–9, 2017},
  url={https://api.semanticscholar.org/CorpusID:160004985}
}

@article{wells2021modal,
  title={Modal decompositions of impulse responses for parametric interaction},
  author={Wells, J. J.},
  journal={Journal of the Audio Engineering Society},
  volume={69},
  number={7/8},
  pages={530--541},
  year={2021},
  publisher={Audio Engineering Society}
}

@inproceedings{badeau2002eds,
  title={EDS parametric modeling and tracking of audio signals},
  author={Badeau, R. and Boyer, R. and David, B.},
  booktitle={Proc. of the 5th International Conference on Digital Audio Effects (DAFx)},
  pages={139--144},
  year={2002}
}

@article{a_journal_paper,
	Author = {Y. Li and J. Cai and Q. Dong and L. Wu and Q. Chen},
	Title = {Psychophysiological Responses of Young  People to Soundscapes in Actual Rural and City Environments},
	Journal = {J. Audio Eng. Soc.},
	Volume = {68},
	Number = {11},
	Pages = {910--925},
	Year = {2020},
	Month = {Dec.},
	note = {https://doi.org/10.17743/jaes.2020.0060.}}

@article{a_journal_paper_with_many_authors,
	Author = {T. Fujioka and C. Freigang and Kie Honjo and J. J. Chen and J. L. Chen and S. E. Black and D. T. Stuff and D. R. Dawson and B. Ross},
	Title = {Central Auditory Processing in Adults with Chronic Stroke Without Hearing Loss: A Magnetoencephalography Study},
	Journal = {Clin. Neurophysiol.},
	Volume = {131},
	Number = {5},
	Pages = {1102--1118},
	Year = {2020},
	Month = {May},
	note = {https://doi.org/10.1016/j.clinph.2020.01.014}}

@article{a_journal_paper_with_article_ID,
	Author = {S. Ntalampiras and I. Potamitis and N. Fakotakis},
	Title = {Exploiting Temporal Feature Integration for Generalized Sound Recognition},
	Journal = {EURASIP J. Adv. Signal Process.},
	Volume = {2009},
	Number = {1},
	Pages = {},
	Year = {2009},
	Month = {Dec.},
	eid = {807162},
	note = {https://doi.org/10.1155/2009/807162}}

A book. The publisher's address and the publication year need to be included in the "publisher" field together with the publisher's name. The first letter of all main words in the title must be capitalized.
@book{a_book_ref,
	author = {V. Pulkki and M. Karjalainen},
	title = {Communication Acoustics: An Introduction to Speech, Audio and Psychoacoustics},
	edition = {},
	publisher = {Wiley},
	address = {Chichester, UK},
	year = {2015}
    }

An example of a book that is not a first edition.
@book{a_book_ref_2nd_edition,
    author = {D. Oram},
    title = {An Individual Note of Music, Sound and Electronics},
    edition = {2},
    publisher = {Anomie Academic},
    address = {Swindon, UK},
    year = {2016}
    }


@book{a_book_ref_2,
	author = {A. Author and B. Bookwriter},
	title = {Dynamic Duos},
	edition = {},
	publisher = {Edda},
	address = {Reykjavik, Iceland},
	year = {1944}
    }
    
@book{a_book_ref_3,
	author = {A. Author and B. Bookwriter and C. Copyeditor},
	title = {Three of a Perfect Pair},
	edition = {},
	publisher = {University of Michigan Press},
	address = {Ann Arbor, Michigan},
	year = {2021}
    }

@book{a_book_ref_M,
	author = {A. Author and B. Bookwriter and others},
	title = {A Very Large Almanac},
	edition = {},
	publisher = {University of Toronto Press},
	address = {Toronto, Canada},
	year = {2112}
    }
    
@book{a_book_ref_N,
	author = {A. Author and others},
	title = {A Book With Lots of Authors},
	edition = {},
	publisher = {TU Vien Academic Press},
	address = {Vienna, Austria},
	year = {1987}
    }

A paper published in a conference/symposium/workshop proceedings. The first letter of all main words in the title must be capitalized. Use a three-letter abbreviation for the month, such as Sep. instead of Sept. 
@conference{a_conference_paper,
    author = {S. J. Schlecht and E. A.P. Habets},
    title = {Accurate Reverberation Time Control in Feedback Delay Networks},
    booktitle = "Proceedings of the International Conference on Digital Audio Effects (DAFx)",
    address = {Edinburgh, UK},
    pages = {337-344},
    month={Sep.},
    year={2017},
    publisher = {},
    }

A reference to a book chapter. 
@incollection{a_book_chapter,
    author = {V. V\"alim\"aki and S. Bilbao and J. O. Smith and J. S. Abel and J. Pakarinen and D. Berners},
    title = {Virtual Analog Effects},
    booktitle = "DAFX---Digital Audio Effects",
    edition = "2",
    editor = {U. Z\"olzer},
    address = {Chichester, UK},
    pages = {473-522},
    month={},
    year={2011},
    publisher = {John Wiley \& Sons},
    }

An AES Convention paper or another meeting or workshop paper without a Proceedings book. The first letter of all main words in the title must be capitalized. Paper number can be inserted in the note field after the word "paper". 
@convention{AES_convention_paper,
	author = {M. Gospodarek and A. Genovese and D. Dembeck and C. Brenner and A. Roginska and K. Perlin},
	booktitle = {147th Convention of the Audio Engineering Society},
	title = {Sound Design and Reproduction Techniques for Co-Located Narrative VR Experiences},
	year = {2019},
	month = {Oct.},
	address = {SOMEWHERE},
	note = {paper 10287},
	}

A doctoral thesis. The first letter of all main words in the title must be capitalized. 
@phdthesis{a_PhD_thesis, 
    author={P. D. L. G. Pestana}, 
    title={Automatic Mixing Systems Using Adaptive Digital Audio Effects}, 
    school = {Universidade Cat\'olica Portuguesa, Porto, Portugal},
    year={2013},
    month={Feb.},
    }
    
A Master's thesis. The first letter of all main words in the title must be capitalized.
@mastersthesis{an_MSc_thesis, 
    author={J. Holm}, 
    title={Applying the Finite Element Method for Modelling Loudspeaker Waveguide Directivity}, school = {Aalto University, Espoo, Finland},
    year={2010},
    month={May},
    }

A patent reference can be formatted using a misc entry type. The first letter of all main words in the title must be capitalized.
@misc{a_patent,
    author = {P. G. Craven and M. A. Gerzon},
    title = {Coincident Microphone Simulation Covering Three Dimensional Space and Yielding Various Directional Outputs},
    howpublished = {{US} Patent 4,042,779},
    year = {1977},
    month = {Aug.}
    }



@conference{abelSimpleRobustMeasure2006,
		title = {A Simple, Robust Measure of Reverberation Echo Density},
		author = {Abel, J. S. and Huang, P.},
		booktitle = {Audio Engineering Society Convention 121},
		month = {Oct.},
		year = {2006},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=13819}
		}

@article{robustLMM,
author = {Schielzeth, H. and Dingemanse, N. J. and Nakagawa, S.and Westneat, D. F. and Allegue, H. and Teplitsky, C. and Réale, D. and Dochtermann, N. A. and Garamszegi, L. Z. and Araya-Ajoy, Y. G.},
title = {Robustness of linear mixed-effects models to violations of distributional assumptions},
journal = {Methods in Ecology and Evolution},
volume = {11},
number = {9},
pages = {1141-1152},
keywords = {biostatistics, correlated predictors, distributional assumptions, linear mixed-effects models, missing random effects, statistical quantification of individual differences (SQuID)},
doi = {https://doi.org/10.1111/2041-210X.13434},
url = {https://besjournals.onlinelibrary.wiley.com/doi/abs/10.1111/2041-210X.13434},
eprint = {https://besjournals.onlinelibrary.wiley.com/doi/pdf/10.1111/2041-210X.13434},
abstract = {Abstract Linear mixed-effects models are powerful tools for analysing complex datasets with repeated or clustered observations, a common data structure in ecology and evolution. Mixed-effects models involve complex fitting procedures and make several assumptions, in particular about the distribution of residual and random effects. Violations of these assumptions are common in real datasets, yet it is not always clear how much these violations matter to accurate and unbiased estimation. Here we address the consequences of violations in distributional assumptions and the impact of missing random effect components on model estimates. In particular, we evaluate the effects of skewed, bimodal and heteroscedastic random effect and residual variances, of missing random effect terms and of correlated fixed effect predictors. We focus on bias and prediction error on estimates of fixed and random effects. Model estimates were usually robust to violations of assumptions, with the exception of slight upward biases in estimates of random effect variance if the generating distribution was bimodal but was modelled by Gaussian error distributions. Further, estimates for (random effect) components that violated distributional assumptions became less precise but remained unbiased. However, this particular problem did not affect other parameters of the model. The same pattern was found for strongly correlated fixed effects, which led to imprecise, but unbiased estimates, with uncertainty estimates reflecting imprecision. Unmodelled sources of random effect variance had predictable effects on variance component estimates. The pattern is best viewed as a cascade of hierarchical grouping factors. Variances trickle down the hierarchy such that missing higher-level random effect variances pool at lower levels and missing lower-level and crossed random effect variances manifest as residual variance. Overall, our results show remarkable robustness of mixed-effects models that should allow researchers to use mixed-effects models even if the distributional assumptions are objectively violated. However, this does not free researchers from careful evaluation of the model. Estimates that are based on data that show clear violations of key assumptions should be treated with caution because individual datasets might give highly imprecise estimates, even if they will be unbiased on average across datasets.},
year = {2020}
}

@misc{kizach2014analyzing,
  title={Analyzing Likert-scale data with mixed-effects linear models: a simulation study},
  author={Kizach, J.},
  year={2014},
  month={feb},
    day={13},
    addendum = {Poster presented at Linguistic Evidence 2014: Empirical, theoretical and computational perspectives - University of Tübingen, Tübingen, Germany}
  
}

@incollection{ahnertRaumakustik2008,
  title = {{Raumakustik}},
  booktitle = {{Handbuch der Audiotechnik}},
  author = {Ahnert, W. and Tennhardt, H.-P.},
  editor = {Weinzierl, Stefan},
  year = {2008},
  series = {{VDI-Buch}},
  pages = {181--266},
  publisher = {{Springer}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-540-34301-1_5},
  urldate = {2023-03-24},
  abstract = {Das Schallfeld einer Schallquelle breitet sich in alle Raumrichtungen ann\"ahernd strahlenf\"ormig aus. Der Anteil des Direktschalls an diesem Schallfeld unter Vernachl\"assigung von reflektiertem und gebeugtem Schallanteil wird als freies Schallfeld bezeichnet. Da die meisten Schallquellen eine schallreflektierende Unterlage benutzen, ist es nach (Fasold et al. 1987) \"ublich, auch dann von einem freien Schallfeld zu sprechen, wenn die Schallquelle auf einer gro\ss en, schallreflektierenden Grundfl\"ache steht. F\"ur Schallquellen in R\"aumen \"uberwiegt in gr\"o\ss erer Entfernung von der Quelle der Anteil von gebeugtem und an den W\"anden reflektiertem Schall. In einem Raum mittlerer Gr\"o\ss e mit einem Volumen von 800~m3 produziert ein Schallsignal innerhalb von nur einer Sekunde etwa 200.000 Reflexionen an den W\"anden, die in den Raum zur\"uckgeworfen werden. Da in diesem Teil des Schallfelds sowohl der \"ortliche Schallpegel als auch die Ausbreitungsrichtungen statistisch weitgehend gleichverteilt sind, wird es als diffuses Schallfeld bezeichnet.},
  isbn = {978-3-540-34301-1},
  langid = {ngerman}
}

@article{doi:10.1177/23312165221092919,
author = {A. Neidhardt and C. Schneiderwind and F. Klein},
title ={Perceptual Matching of Room Acoustics for Auditory Augmented Reality in Small Rooms - Literature Review and Theoretical Framework},
journal = {Trends in Hearing},
volume = {26},
number = {},
pages = {23312165221092919},
year = {2022},
doi = {10.1177/23312165221092919},
    note ={PMID: 35505625},

URL = { 
        https://doi.org/10.1177/23312165221092919
    
},
eprint = { 
        https://doi.org/10.1177/23312165221092919
    
}
,
    abstract = { For the realization of auditory augmented reality (AAR), it is important that the room acoustical properties of the virtual elements are perceived in agreement with the acoustics of the actual environment. This perceptual matching of room acoustics is the subject reviewed in this paper. Realizations of AAR that fulfill the listeners’ expectations were achieved based on pre-characterization of the room acoustics, for example, by measuring acoustic impulse responses or creating detailed room models for acoustic simulations. For future applications, the goal is to realize an online adaptation in (close to) real-time. Perfect physical matching is hard to achieve with these practical constraints. For this reason, an understanding of the essential psychoacoustic cues is of interest and will help to explore options for simplifications. This paper reviews a broad selection of previous studies and derives a theoretical framework to examine possibilities for psychoacoustical optimization of room acoustical matching. }
}

@article{kaplanisPerceptionPreferenceReverberation2019,
  title = {Perception and Preference of Reverberation in Small Listening Rooms for Multi-Loudspeaker Reproduction},
  author = {Kaplanis, N. and Bech, S. and Lokki, T. and {van Waterschoot}, T. and H. Jensen, S.},
  year = {2019},
  month = nov,
  journal = {The Journal of the Acoustical Society of America},
  volume = {146},
  number = {5},
  pages = {3562--3576},
  issn = {0001-4966},
  doi = {10.1121/1.5135582},
  note = {doi: 10.1121/1.5135582},
  urldate = {2022-08-22},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/L8IBLGT5/Kaplanis et al. - 2019 - Perception and preference of reverberation in smal.pdf}
}

@inproceedings{porschmannBinauralAuralizationProposed2017,
  title = {Binaural Auralization of Proposed Room Modifications Based on Measured Omnidirectional Room Impulse Responses},
  booktitle = {173rd {{Meeting}} of {{Acoustical Society}} of {{America}} and 8th {{Forum Acusticum}}},
  author = {P{\"o}rschmann, C. and Stade, P. and Arend, J. M.},
  year = {2017},
  address = {Boston, Massachusetts},
  doi = {10.1121/2.0000622},
  note = {doi: 10.1121/2.0000622},
  urldate = {2022-11-30},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/BDDFUWAX/Pörschmann et al. - 2017 - Binaural auralization of proposed room modificatio.pdf}
}
@Inproceedings{Schneiderwind2021,
  author       = {Schneiderwind, C. and Neidhardt, A. and Meyer, D.},
  title        = {Comparing the effect of different open headphone models on the perception of a real sound source},
  booktitle    = {150th AES Convention, Online, 2021},
  year         = {2021},
  month        = may,
}

@article{amengualgariFlexibleBinauralResynthesis2019,
  title = {Flexible Binaural Resynthesis of Room Impulse Responses for Augmented Reality Research},
  author = {Amengual Gari, S. V. and Brimijoin, W. O. and Hassager, H. G. and Robinson, P. W.},
  year = {2019},
  journal = {{EAA Spatial Audio Signal Processing Symposium}},
  doi = {10.25836/SASP.2019.31},
  note = {doi: 10.25836/SASP.2019.31},
  urldate = {2023-02-15},
  abstract = {A basic building block of audio for Augmented Reality (AR) is the use of virtual sound sources layered on top of real sources present in an environment. In order to perceive these virtual sources as belonging to the natural scene it is important to carefully replicate the room acoustics of the listening space. However, it is unclear to what extent the real and virtual room impulse responses (RIR) need to be matched in order to generate plausible scenes in which virtual sound sources blend seamlessly with real sound sources. This contribution presents an auralization framework that allows binaural rendering, manipulation and reproduction of room acoustics in augmented reality scenarios, in order to get a better understanding of the perceptual relevance of individual room acoustic parameters. Auralizations are generated from measured multichannel room impulse responses (MRIR) parametrized using the Spatial Decomposition Method (SDM). An alternative method to correct the known time-dependent coloration of SDM based auralizations is presented. Instrumental validation shows that re-synthesized binaural room impulse responses (BRIRs) are in close agreement with measured BRIRs. In situ perceptual validation with expert listeners show that - in the presence of visual cues, an explicit sound reference and unlimited listening time, they are able to discriminate between a real loudspeaker and its re-synthesized version. However, the renderings appear to be as plausible as a real source once visual cues are removed. Finally, approaches to manipulate the spatial and time-energy properties of the auralizations are presented.},
  langid = {english},
  keywords = {Augmented Reality,Binaural,Perception,Room Acoustics},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/AHC9NN8M/Amengual Gari et al. - 2019 - Flexible binaural resynthesis of room impulse resp.pdf}
}

@article{amengualgariOptimizationsSpatialDecomposition2021,
  title = {Optimizations of the {{Spatial Decomposition Method}} for {{Binaural Reproduction}}},
  author = {Amengual Gar{\'i}, S. V. and Arend, J. M. and Calamia, P. T. and Robinson, P. W.},
  year = {2021},
  month = jan,
  journal = {Journal of the Audio Engineering Society},
  volume = {68},
  number = {12},
  pages = {959--976},
  issn = {15494950},
  doi = {10.17743/jaes.2020.0063},
  urldate = {2022-11-29},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/4CDQPWBK/ARpresence.pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/5FRFNWGA/Amengual Garí et al. - 2021 - Optimizations of the Spatial Decomposition Method .pdf}
}

@incollection{andoConcertHallAcoustics2014,
  title = {Concert {{Hall Acoustics Based}} on {{Subjective Preference Theory}}},
  booktitle = {Springer {{Handbook}} of {{Acoustics}}},
  author = {Ando, Yoichi},
  editor = {Rossing, Thomas D.},
  year = {2014},
  pages = {367--402},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4939-0755-7_10},
  note = {isbn: 978-1-4939-0754-0, 978-1-4939-0755-7},
  urldate = {2023-03-06},
  isbn = {978-1-4939-0754-0 978-1-4939-0755-7},
  langid = {english}
}


@techreport{ANSIS111,
address = {New York, USA},
type = {Standard},
title = {Specifications for Octave-Band and Fractional-Octave-Band Analog and Digital Filters},
shorttitle = {ANSI S1.11},
language = {en},
number = {ANSI S1.11},
institution = {Acoustical Society of America},
author = {ANSI},
year = {1993}
}


@Article{GilCarvajal2016,
  author    = {Gil-Carvajal, J. C. and Cubick, J. and Santurette, S. and Dau, T.},
  title     = {Spatial hearing with incongruent visual or auditory room cues},
  journal   = {Scientific reports},
  year      = {2016},
  volume    = {6},
  number    = {1},
  pages     = {1--10},
  doi       = {10.1038/srep37342},
}

@Article{UDESEN2015,
  author    = {Udesen, J. and Piechowiak, T. and Gran, F.},
  title     = {The effect of vision on psychoacoustic testing with headphone-based virtual sound},
  journal   = {J. Audio Eng. Soc.},
  year      = {2015},
  volume    = {63},
  number    = {7/8},
  pages     = {552--561},
  month     = jul,
  doi       = {10.17743/jaes.2015.0061},
}

@article{antoniOrthogonallikeFractionaloctavebandFilters2010,
  title = {Orthogonal-like Fractional-Octave-Band Filters},
  author = {Antoni, J.},
  year = {2010},
  month = feb,
  journal = {The Journal of the Acoustical Society of America},
  volume = {127},
  number = {2},
  pages = {884--895},
  issn = {0001-4966},
  doi = {10.1121/1.3273888},
  note = {doi: 10.1121/1.3273888},
  urldate = {2022-10-07},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/UEGWQLG4/Antoni - 2010 - Orthogonal-like fractional-octave-band filters.pdf}
}

@article{arendSixDegreesofFreedomParametricSpatial2021,
  title = {Six-{{Degrees-of-Freedom Parametric Spatial Audio Based}} on {{One Monaural Room Impulse Response}}},
  author = {Arend, J. M. and Gar{\'i}, S. V. Amengual and Schissler, C. and Klein, F. and Robinson, P. W.},
  year = {2021},
  month = nov,
  journal = {Journal of the Audio Engineering Society},
  volume = {69},
  number = {7/8},
  pages = {557--575},
  issn = {15494950},
  doi = {10.17743/jaes.2021.0009},
  urldate = {2023-03-16},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/HL58WZ28/Arend et al. - 2021 - Six-Degrees-of-Freedom Parametric Spatial Audio Ba.pdf}
}

@article{azumaSurveyAugmentedReality,
  title = {A {{Survey}} of {{Augmented Reality}}},
  author = {Azuma, R. T.},
  abstract = {This paper surveys the field of Augmented Reality, in which 3-D virtual objects are integrated into a 3-D real environment in real time. It describes the medical, manufacturing, visualization, path planning, entertainment and military applications that have been explored. This paper describes the characteristics of Augmented Reality systems, including a detailed discussion of the tradeoffs between optical and video blending approaches. Registration and sensing errors are two of the biggest problems in building effective Augmented Reality systems, so this paper summarizes current efforts to overcome these problems. Future directions and areas requiring further research are discussed. This survey provides a starting point for anyone interested in researching or using Augmented Reality.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/8X47R92I/Azuma - A Survey of Augmented Reality.pdf}
}

@article{bernschutzMicrophoneArraysSound2016,
  title = {Microphone Arrays and Sound Field Decomposition for Dynamic Binaural Recording},
  author = {Bernsch{\"u}tz, B.},
  year = {2016},
  publisher = {{Technische Universit\"at Berlin}},
  doi = {10.14279/DEPOSITONCE-5082},
  urldate = {2023-03-08},
  abstract = {Die Dissertation behandelt ein feldbezogenes r\"aumliches Audioaufnahmeverfahren, das auf Mikrofonarrays und orthogonaler Schallfeldzerlegung beruht und eine geeignete Beschreibung f\"ur dynamische binaurale Wiedergabe liefert. Dynamische binaurale Wiedergabe bezeichnet ein meist kopfh\"orerbasiertes r\"aumliches Audiowiedergabeverfahren zur Darbietung lokalisierbarer virtueller Schallquellen, das die Kopfbewegung des Rezipienten ber\"ucksichtigt, um sie von der r\"aumlichen Orientierung der wiedergegeben virtuellen auditorischen Szene zu entkoppeln. Die wesentlichen Vorteile gegen\"uber statischer binauraler Wiedergabe bestehen in einer verbesserten Lokalisation und Externalisierung der virtuellen Quellen, sowie der M\"oglichkeit, statische oder dynamische virtuelle Quellen wiederzugeben, die unabh\"angig von der Kopfbewegung des Rezipienten ortsfest verbleiben oder sich in Bezug zu einem statischen weltbezogenen Koordinatensystem bewegen. Dynamische binaurale Wiedergabe setzt entweder objektbasierte Audioproduktion oder spezifische feldbezogene Aufnahmeverfahren voraus. Letztere liegen im Fokus dieser Arbeit. Der Einsatz von Mikrofonarrays in Kombination mit orthogonaler Schallfeldzerlegung stellt hierzu einen vielversprechenden L\"osungsansatz dar. Das Verfahren beruht auf einer eleganten mathematisch geschlossenen L\"osung. Kopfbewegungen des Rezipienten k\"onnen in allen rotatorischen Freiheitsgraden ber\"ucksichtigt werden. In der Theorie lassen sich auch translatorische Freiheitsgrade einbeziehen. Durch Einsatz individueller kopfbezogener \"Ubertragungsfunktionen (HRTFs) kann die Wiedergabe individualisiert werden. Das Verfahren eignet sich f\"ur Punkt-zu-Mehrpunkt \"Ubertragung. Aufgrund enger mathematischer Verwandtschaft zum higher-order Ambisonics (HOA) Verfahren, lassen sich die dort eingesetzten Formate und Codecs zur Speicherung und \"Ubertragung der Audiodaten nutzen. Unter Annahme idealer physikalischer Bedingungen wird zun\"achst der theoretische Ansatz diskutiert und eine mathematisch geschlossene L\"osung abgeleitet. Aufgrund verschiedener Einschr\"ankungen in technischen Systemen, wie beispielsweise raumdiskrete Abtastung oder Rauschen in den Signalwegen, sind in der Praxis allerdings keine idealen Bedingungen erzielbar. Die wichtigsten Einschr\"ankungen werden aufgezeigt und ihr jeweiliger Einfluss auf das Systemverhalten untersucht. Verschiedene Methoden zur Verbesserung der \"Ubertragungseigenschaften werden diskutiert. In H\"orversuchen werden perzeptive Eigenschaften des Systems im Hinblick auf spezifische technische Einschr\"ankungen sowie realistische Bedingungen evaluiert. Ferner werden optimale Systemparameter ermittelt. Es zeigt sich, dass arraybasierte Systeme f\"ur die feldbezogene dynamische Binauralaufnahme mit guten perzeptiven Eigenschaften unter vertretbarem technischen und wirtschaftlichen Aufwand realisierbar sind.},
  collaborator = {Technische Universit{\"a}t Berlin and Technische Universit{\"a}t Berlin and Weinzierl, Stefan},
  langid = {english},
  keywords = {3D-Audio,620 Ingenieurwissenschaften,621 Angewandte Physik,Aufnahmetechnik,binaural technology,Binauraltechnik,microphone arrays,mikrofonarrays,Schallfeldzerlegung,sound field decomposition,sound recording,spatial audio},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/G2RLRT7C/Bernschütz - 2016 - Microphone arrays and sound field decomposition fo.pdf}
}

@article{bestIntroductionPsychologicalPhysiological2021,
  title = {An Introduction to {{Psychological}} and {{Physiological}} Acoustics},
  author = {Best, V.},
  year = {2021},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {150},
  number = {4},
  pages = {A133-A134},
  issn = {0001-4966},
  doi = {10.1121/10.0007879},
  urldate = {2022-08-18},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/SEM4HASG/Best - 2021 - An introduction to Psychological and Physiological.pdf}
}

@book{blauertAcousticsEngineers2009,
  title = {Acoustics for {{Engineers}}},
  author = {Blauert, J. and Xiang, N.},
  year = {2009},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-03393-3},
  urldate = {2023-01-31},
  isbn = {978-3-642-03392-6 978-3-642-03393-3},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/TH6LU9RI/Blauert and Xiang - 2009 - Acoustics for Engineers.pdf}
}

@inbook{blauertSpatialHearingMultiple1996,
  title = {Spatial {{Hearing}} with {{Multiple Sound Sources}} and in {{Enclosed Spaces}}},
  booktitle = {Spatial {{Hearing}}},
  year = {1996},
  month = oct,
  edition = {Second},
  pages = {215--301},
  publisher = {{The MIT Press}},
  doi = {10.7551/mitpress/6391.003.0007},
  urldate = {2023-02-05},
  author = {Blauert, J.},
  address = {Cambridge, Massachusetts},
  isbn = {978-0-262-26868-4},
  note = {isbn: 978-0-262-26868-4},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/5YH7CDQC/blauert0.pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/74KGZNBA/1996 - Spatial Hearing with Multiple Sound Sources and in.pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/PZDMVYVP/blauert1.pdf}
}


@book{blauertSpatialHearingPsychophysics1996,
  added-at = {2009-03-10T17:44:20.000+0100},
  author = {{J. Blauert}},
  biburl = {https://www.bibsonomy.org/bibtex/28924a1ddc5198971ed3732e9bdb73334/pagauthier},
  description = {Livres : acoustiques, vibrations, etc. (PAG)},
  interhash = {85407effd0c5b74f5ef438c2c88e2141},
  intrahash = {8924a1ddc5198971ed3732e9bdb73334},
  keywords = {Book},
  publisher = {The MIT Press},
  address = {Cambridge, Massachusetts},
  note = {isbn: 978-262-02413-6},
  edition = {Revised},
  title = {Spatial hearing -- The psychophysics of human sound localization},
  year = 1997
}


@book{blauertTechnologyBinauralListening2013,
  title = {The {{Technology}} of {{Binaural Listening}}},
  editor = {Blauert, J.},
  year = {2013},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  doi = {10.1007/978-3-642-37762-4},
  urldate = {2023-01-29},
  isbn = {978-3-642-37761-7 978-3-642-37762-4},
  note = {isbn: 978-3-642-37761-7, 978-3-642-37762-4},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/UN549Z34/Blauert - 2013 - The Technology of Binaural Listening.pdf}
}

@book{blauertTechnologyBinauralUnderstanding2020,
  title = {The {{Technology}} of {{Binaural Understanding}}},
  editor = {Blauert, J. and Braasch, J.},
  year = {2020},
  series = {Modern {{Acoustics}} and {{Signal Processing}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-00386-9},
  urldate = {2023-02-23},
  isbn = {978-3-030-00385-2 978-3-030-00386-9},
  note = {isbn: 978-3-030-00385-2, 978-3-030-00386-9},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/4AFL4CBW/Blauert and Braasch - 2020 - The Technology of Binaural Understanding.pdf}
}

@inproceedings{blevinsQuantifyingJustNoticeable,
author = {Blevins, M. G and Buck, A. and Peng, Z. E. and Wang, L.},
year = {2013},
month = {June},
booktitle = {International Symposium on Room Acoustics 2013 June 9-11},
address= {Toronto, Canada},
pages = {},
title = {Quantifying the Just Noticeable Difference of Reverberation Time with Band-Limited Noise Centered around 1000 {{Hz}} Using a Transformed up-down Adaptive Method},
}


@article{bonselStudyEffectsBRIR2014,
  title = {Study on Effects of {{BRIR}} Set on Quality Assessment},
  author = {B{\"o}nsel, C. and B{\"o}hme, M. and Goecke, D. and Klein, F. and Schnemilich, M. and Sporer, T. and Werner, S. and Wolf, M. and W{\"u}rsig, A. and Mayenfels, T.},
  year = {2014},
  month = aug,
  volume = {55},
  journal = {AES Conference on Spatial Audio},
  address = {Helsinki, Finland},
  abstract = {Next to an adequate technical realization of an audio reproduction system, the context of usage plays a major role if a perfect auditory illusion with immersion and plausibility is aspired. This contribution presents results from perceptual experiments on context dependent quality parameters. A binaural synthesis of an acoustic scene via a personalized headphone system is used. The investigated quality parameters are influenced by divergence between synthesized scene and listening room, visibility of the scene, and personalization of the system. The plausibility of the perceived auditory scene is described by the test persons with the help of the quality features perceived externalization and direction of the auditory event. The analysis shows that there are significant differences in perceived externalization depending on the occurrence of localization errors but also on divergence or congruence between the listening and synthesized room.}
}

@book{boslaughStatisticsNutshell2012,
  title = {Statistics in a Nutshell},
  author = {Boslaugh, S.},
  year = {2012},
  series = {In a Nutshell},
  edition = {2nd ed},
  publisher = {{O'Reilly}},
  address = {{Farnham, Surrey, England}},
  abstract = {A clear and concise introduction and reference for anyone new to the subject of statistics},
  isbn = {978-1-4493-1682-2},
  langid = {english},
  lccn = {QA276.12 .B67 2012},
  keywords = {Problems; exercises; etc,Statistics},
  annotation = {OCLC: ocn820127295},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/ATY3RM2N/Boslaugh - 2012 - Statistics in a nutshell.pdf}
}

@book{brandenburgApplicationsDigitalSignal1998,
  title = {Applications of Digital Signal Processing to Audio and Acoustics},
  author = {Brandenburg, K. and Kahrs, M.},
  year = {1998},
  publisher = {{Kluwer}},
  address = {{Boston}},
  urldate = {2022-08-18},
  abstract = {Today, the main applications of audio DSP are high quality audio coding and the digital generation and manipulation of music signals. They share common research topics including perceptual measurement techniques and analysis/synthesis methods. Additional important topics are hearing aids using signal processing technology and hardware architectures for digital signal processing of audio. In all these areas the last decade has seen a significant amount of application oriented research. This book is suitable for advanced level courses and serves as a valuable reference for researchers in the field. Interested and informed engineers will also find the book to be useful in their work.},
  isbn = {9780792381303 9780306470424 9786610205950},
  langid = {english},
  annotation = {OCLC: 150645742},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/S2MSVDYV/Brandenburg and Kahrs - 1998 - Applications of digital signal processing to audio.pdf}
}

@article{brinkmannAuthenticityIndividualDynamic2017,
  title = {On the Authenticity of Individual Dynamic Binaural Synthesis},
  author = {Brinkmann, F. and Lindau, A. and Weinzierl, S.},
  year = {2017},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {142},
  number = {4},
  pages = {1784--1795},
  issn = {0001-4966},
  doi = {10.1121/1.5005606},
  urldate = {2023-01-13},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/ZWVAYE6V/Brinkmann et al. - 2017 - On the authenticity of individual dynamic binaural.pdf}
}


@article{cabreraAcousticclarityAuditoryRoom2007,
  title = {Acousticclarity and Auditory Room Size Perception},
  author = {Cabrera, D.},
  year = {2007},
  journal = {14th Int. Congress on Sound \& Vibration, Cairns, Australia},
  pages = {9--12},
  abstract = {Studies of auditory room size perception have sometimes found clarity index to be a good first order predictor of subjective ratings, with a negative correlation coefficient. However, for rooms of fixed reverberation time, the slope of the function relating clarity index to room volume is positive (for a given source-receiver distance). This paper considers how clarity index relates to room volume for realistic rooms, and why it can be an effective predictor of perceived room size.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/ESJQJHNJ/Cabrera - 2007 - ACOUSTIC CLARITY AND AUDITORY ROOM SIZE PERCEPTION.pdf}
}

@book{cavanaughArchitecturalAcousticsPrinciples2010,
  title = {Architectural Acoustics: Principles and Practice},
  shorttitle = {Architectural Acoustics},
  editor = {Cavanaugh, W. J. and Tocci, G. C. and Wilkes, J. A.},
  year = {2010},
  edition = {2nd ed},
  publisher = {{John Wiley \& Sons}},
  address = {{Hoboken, N.J}},
  isbn = {978-0-470-19052-4},
  lccn = {NA2800 .A685 2010},
  keywords = {Architectural acoustics},
  annotation = {OCLC: ocn316737162}
}

@article{choeVentriloquistEffectVisual1975,
  title = {The ``Ventriloquist Effect'': {{Visual}} Dominance or Response Bias?},
  shorttitle = {The ``Ventriloquist Effect''},
  author = {Choe, C. S. and Welch, R. B. and Gilford, R. M. and Juola, J. F.},
  year = {1975},
  month = jan,
  journal = {Perception \& Psychophysics},
  volume = {18},
  number = {1},
  pages = {55--60},
  issn = {0031-5117, 1532-5962},
  doi = {10.3758/BF03199367},
  note = {doi: 10.3758/BF03199367},
  urldate = {2023-03-28},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/TZ5BM22C/Choe et al. - 1975 - The “ventriloquist effect” Visual dominance or re.pdf}
}


@conference{colemanObjectbasedAudioReverberation2016,
		title = {On Object-Based Audio with Reverberation},
		author = {Coleman, P. and Franck, A. and Jackson, P. and Hughes, R. and Remaggi, L. and Melchior, F.},
		booktitle = {Audio Engineering Society Conference: 60th International Conference: DREAMS (Dereverberation and Reverberation of Audio, Music, and Speech)},
		month = {Jan},
		year = {2016},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=18071}
		}

@book{cremerWissenschaftlichenGrundlagenRaumakustik1976,
  title = {Die Wissenschaftlichen {{Grundlagen}} Der {{Raumakustik}}},
  author = {Cremer, L. and M{\"u}ller, H. A.},
  year = {1976},
  edition = {2., v\"ollig neubearb. Aufl},
  publisher = {{Hirzel}},
  address = {{Stuttgart}},
  isbn = {978-3-7776-0315-5},
  lccn = {NA2800 .C7 1976},
  keywords = {Architectural acoustics}
}

@book{dauAuditoryPlasticityListening2014,
  title = {Auditory Plasticity - Listening with the Brain},
  editor = {Dau, T.},
  year = {2014},
  publisher = {{Danavox Jubilee Foundation}},
  address = {{Ballerup}},
  isbn = {978-87-990013-4-7},
  langid = {english},
  annotation = {OCLC: 900425293},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/W3L7FSA5/Dau - 2014 - Auditory plasticity - listening with the brain.pdf}
}

@article{dbt_mods_00039972,
  title = {Data Set: {{BRIRs}} for Position-Dynamic Binaural Synthesis Measured in Two Rooms},
  author = {Neidhardt, A. and {International Conference on Spatial Audio (ICSA); 5 (Ilmenau) : 2019.09.26-28}},
  editor = {Werner, Stephan and G{\"o}ring, Steve},
  year = {2019},
  month = nov,
  journal = {Audio for Virtual, Augmented and Mixed Realities: Proceedings of ICSA 2019 ; 5th International Conference on Spatial Audio ; September 26th to 28th, 2019, Ilmenau, Germany},
  pages = {165--169},
  address = {{Ilmenau}},
  doi = {10.22032/dbt.39936},
  abstract = {The ICSA 2019 focuses on a multidisciplinary bringing together of developers, scientists, users, and content creators of and for spatial audio systems and services. A special focus is on audio for so-called virtual, augmented, and mixed realities. The fields of ICSA 2019 are: - Development and scientific investigation of technical systems and services for spatial audio recording, processing and reproduction / - Creation of content for reproduction via spatial audio systems and services / - Use and application of spatial audio systems and content presentation services / - Media impact of content and spatial audio systems and services from the point of view of media science. The ICSA 2019 is organized by VDT and TU Ilmenau with support of Fraunhofer Institute for Digital Media Technology IDMT.},
  langid = {english},
  keywords = {Audiotechnik,Elektroakustik,Technische Akustik}
}

@article{defranceUsingMatchingPursuit2009,
  title = {Using {{Matching Pursuit}} for {{Estimating Mixing Time Within Room Impulse Responses}}},
  author = {Defrance, G. and Daudet, L. and Polack, J.-D.},
  year = {2009},
  month = nov,
  journal = {Acta Acustica united with Acustica},
  volume = {95},
  number = {6},
  pages = {1071--1081},
  issn = {16101928},
  doi = {10.3813/AAA.918239},
  urldate = {2023-03-03},
  langid = {english}
}

@article{demanPerceptualEvaluationAnalysis2017,
  title = {Perceptual {{Evaluation}} and {{Analysis}} of {{Reverberation}} in {{Multitrack Music Production}}},
  author = {{de Man}, B. and McNally, K. and Reiss, J.},
  year = {2017},
  month = feb,
  journal = {Journal of the Audio Engineering Society},
  volume = {65},
  number = {1/2},
  pages = {108--116},
  issn = {15494950},
  doi = {10.17743/jaes.2016.0062},
  urldate = {2022-08-25},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/KZRCZD4M/1.4949365.pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/UGU9RUIG/de Man et al. - 2017 - Perceptual Evaluation and Analysis of Reverberatio.pdf}
}

@inproceedings{dziwisMachineLearningBasedRoom2021,
  title = {Machine {{Learning-Based Room Classification}} for {{Selecting Binaural Room Impulse Responses}} in {{Augmented Reality Applications}}},
  booktitle = {2021 {{Immersive}} and {{3D Audio}}: From {{Architecture}} to {{Automotive}} ({{I3DA}})},
  author = {Dziwis, D. and Zimmermann, S. and Lubeck, T. and Arend, J. M. and Bau, D. and Porschmann, C.},
  year = {2021},
  month = sep,
  pages = {1--8},
  publisher = {{IEEE}},
  address = {{Bologna, Italy}},
  doi = {10.1109/I3DA48870.2021.9610915},
  urldate = {2022-08-10},
  abstract = {A key attribute of augmented reality (AR) applications is the matching reverberation of virtual sounds to the room acoustics of the real environment. However, especially in real-time scenarios where the properties of rapidly changing surroundings are unknown, creating a persistently coherent sound field synthesis within a real space is a challenging problem. While AR devices and their sensors can usually provide depth information within the field of view of the user, retrieving a complete geometric model requires significant time and user activity. Prior acoustic measurements or scans of the deployment area also severely limit many use cases, especially in the consumer sector. In this paper, we propose an automatic system that provides a fast selection of room categories and their corresponding binaural reverberation using only monoscopic images as input information. The proposed system combines existing approaches of machine learning (ML) based room classification and parametric synthesis of binaural room impulse responses (BRIRs) to provide room reverberation for arbitrary indoor environments. As a proof of concept, we present a demonstrator developed in Cycling'74s Max linked to a python-based ML model. For the ML model, we use the convolutional neural network (CNN) GoogLeNet architecture trained on a subset of the Places365 data set. This subset contains 20 custom indoor room categories which are composed of the original categories that share similar acoustic properties. The demonstrator captures images and automatically selects binaural reverberation based on the predictions of the ML classifier. Monophonic stimuli are reverberated and presented using dynamic headphone-based binauralization.},
  isbn = {978-1-66540-998-8},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/TKVCX95V/Dziwis et al. - 2021 - Machine Learning-Based Room Classification for Sel.pdf}
}

@article{FeatureAnalysisReverberation,
  title = {Feature Analysis for the Reverberation Perception in Speech Signals},
  pages = {5},
  abstract = {This paper considers the problem of quantifying the reverberation perception on speech signals. We investigate several combinations of three distinct reverberation-related features (namely, the reverberation time (RT), room spectral variance (RSV), and direct-toreverberant energy ratio (DRR)), which can be extracted directly from the associated room impulse response. Particular attention is also paid on different post-processing nonlinear mappings in order to provide a more effective quality evaluation algorithm. Results indicate that the RSV feature can be completely disregarded if the RT and DRR estimates are properly weighted. Performance of resulting measure is slightly superior in comparison to previous state-of-theart method, particularly with respect to the computational cost and robustness (by disregarding the RSV estimation), but also on the statistical correlation level with subjective grades of a large dataset of reverberant speech.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/BQDLR5JU/Feature analysis for the reverberation perception .pdf}
}

@inproceedings{frissenEffectSoundSource2010,
  title = {Effect of Sound Source Stimuli on the Perception of Reverberation in Large Volumes},
  booktitle = {Auditory Display},
  author = {Frissen, I. and Katz, B. F. G. and Guastavino, C.},
  editor = {Ystad, S{\o}lvi and Aramaki, Mitsuko and {Kronland-Martinet}, Richard and Jensen, Kristoffer},
  year = {2010},
  pages = {358--376},
  publisher = {{Springer Berlin Heidelberg}},
  address = {{Berlin, Heidelberg}},
  abstract = {The aim of the presented research is to determine whether the perception of reverberation is dependent on the type of sound stimuli used. We quantified the discrimination thresholds for reverberations that are representative for large rooms such as concert halls (reverberation times around 1.8 s). For exponential decays, simulating an ideal simple room, thresholds are around 6\% (Experiment 1). We found no difference in thresholds between a short noise burst and a male voice spoken word, suggesting that discrimination is not dependent on the type, or spectral content, of the sound source (Experiment 2). In two further experiments using a magnitude estimation paradigm we assessed the perceived amount of reverberation as a function of various types of stimuli. Whereas the discrimination of reverberant stimuli does not seem to be affected by the sound stimulus, the perceived amount of reverberation is affected. Vocal stimuli are perceived as being more reverberant than non-vocal stimuli. The results are discussed in light of current neuroscientific models of auditory processing of complex stimuli but also with respect to their consequences for the use of reverberation in auditory display.},
  isbn = {978-3-642-12439-6},
  note = {isbn: 978-3-642-12439-6}
}

@article{fugControlledAuditoryDistance2012a,
  title = {Controlled {{Auditory Distance Perception}} Using {{Binaural Headphone Reproduction}} \textendash{} {{Algorithms}} and {{Evaluation}}},
  author = {F{\"u}g, S. and Werner, S. and Brandenburg, K.},
  month = {Nov.},
  year = {2012},
  journal = {VDT Int. Convention, 27. Tonmeistertagung},
  abstract = {For a realistic audio playback, it is reasonable to be able to reproduce the distance of a sound source in addition to the direction. Based on a Master's thesis at the Ilmenau University of Technology, two algorithms for the controlled modification of auditory distance perception are presented for binaural headphone reproduction. The implementation of these algorithms is based on an extensive analysis of measured Binaural Room Impulse Responses (BRIR) and a detailed research of the mechanisms of human auditory distance perception. The two algorithms vary systematically selected distance-dependent properties of Binaural Room Impulse Responses, such as the Initial Time Delay Gap (ITDG), the Energy Decay Curve (EDC) and selected energy ratios, as well as reverberation characteristics. By calculating modified BRIRs by applying the algorithms on a single measured BRIR from one fixed distance and using them for binaural headphone reproduction, it is possible to control auditory distance perception. Listening tests were accomplished to test the perceptual effects of using the synthesized BRIRS for binaural headphone reproduction. The perceived distance of sound sources was surveyed by a multi stimulus test.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/HNJ6INRB/Füg et al. - 2012 - Controlled Auditory Distance Perception using Bina.pdf}
}

@article{gardnerHRTFMeasurementsKEMAR1994,
  title = {{{HRTF Measurements}} of a {{KEMAR Dummy-Head Microphone}}},
  author = {Gardner, B. and Martin, K.},
  year = {1994},
  month = may,
  journal = {MIT Media Lab Machine Listening Group},
  abstract = {An extensive set of head-related transfer function (HRTF1) measurements of a KEMAR dummy head microphone has recently been completed. The measurements consist of the left and right ear impulse responses from a Realistic Optimus Pro 7 loudspeaker mounted 1.4 meters from the KEMAR. Maximum length (ML) pseudo-random binary sequences were used to obtain the impulse responses at a sampling rate of 44.1 kHz. In total, 710 di erent positions were sampled at elevations from -40 degrees to +90 degrees. Also measured were the impulse response of the speaker in free eld and several headphones placed on the KEMAR. This data is being made available to the research community on the Internet via anonymous FTP and the World Wide Web.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/S9E2AND8/Gardner and Martin - HRTF Measurements of a KEMAR Dummy-Head Microphone.pdf}
}

@inproceedings{gariDeterminingThresholdsRoom2021,
  title = {Towards Determining Thresholds for Room Divergence: {{A}} Pilot Study on Perceived Externalization},
  shorttitle = {Towards Determining Thresholds for Room Divergence},
  booktitle = {2021 {{Immersive}} and {{3D Audio}}: From {{Architecture}} to {{Automotive}} ({{I3DA}})},
  author = {Gari, S. V. Amengual and Hassager, H. G. and Klein, F. and Arend, J. M. and Robinson, P. W.},
  year = {2021},
  month = sep,
  pages = {1--7},
  publisher = {{IEEE}},
  address = {{Bologna, Italy}},
  doi = {10.1109/I3DA48870.2021.9610835},
  urldate = {2022-08-18},
  abstract = {In binaural rendering, the room divergence effect refers to the decrease on perceived externalization due to the mismatch between the room acoustics of the virtual sounds and those of the listening space. In this work we report on the results of a 2-AFC pilot experiment where 5 expert subjects evaluated the impact of the room divergence effect by comparing real sources and head-tracked virtual sounds generated using the Binaural Spatial Decomposition Method (BSDM) presented over headphones. By applying an exponential weighting function on the measured room impulse responses (RIR) we render binaural RIRs with arbitrary reverberation time (RT), ranging from 50\% to 150\% of the original RT, while maintaining the temporal and spatial patterns of the original RIR. Preliminary results for a test conducted in a small room (RT 0.55 s at 1 kHz) suggest that the perceived externalization degree depends on the played stimulus, and progressively degrades with an increasing mismatch. Castanets sounds present externalization ratings comparable to those of a real loudspeaker for RTs ranging from {$\sim$}90\% to {$\sim$}125\%, while for male speech the externalization ratings degrade significantly for sounds with RTs greater than {$\sim$}110\%. Furthermore, we discuss the potential effects of listener adaptation to virtual sounds and its impact on the externalization ratings.},
  isbn = {978-1-66540-998-8},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/X8MHIXHV/Gari et al. - 2021 - Towards determining thresholds for room divergence.pdf}
}

@article{gimenezMismatchesObjectiveParameters2014,
  title = {Mismatches between Objective Parameters and Measured Perception Assessment in Room Acoustics: {{A}} Holistic Approach},
  shorttitle = {Mismatches between Objective Parameters and Measured Perception Assessment in Room Acoustics},
  author = {Gim{\'e}nez, A. and Cibri{\'a}n, R. M. and Cerd{\'a}, S. and Gir{\'o}n, S. and Zamarre{\~n}o, T.},
  year = {2014},
  month = apr,
  journal = {Building and Environment},
  volume = {74},
  pages = {119--131},
  issn = {03601323},
  doi = {10.1016/j.buildenv.2013.12.022},
  urldate = {2022-08-22},
  abstract = {Psychoacoustic research in the field of concert halls has revealed that many aspects concerning listening perception have yet to be totally understood. On the one hand, the objective room acoustics of performance spaces are reflected in parameters, some standardized and some not, but these are related to a limited number of perceptual attributes of human response. In general, these objective parameters cannot accurately describe the acoustic details due to their inherent simplification. Under these premises, impulse responses (576 receivers) are measured in 16 concert halls, according to standard procedures, and the perception and satisfaction of the occupants of the rooms are evaluated by completing a questionnaire during live concerts. Correlation analyses and multidimensional scaling (MDS) techniques have been applied to spatial and multi-band averaged values of the acoustic parameters studied (18), and the average values of users' responses (1284) to the questionnaire items (26). As a first result, correlations between objective parameters and users' responses show that transversality exists between them. Secondly, hierarchical clustering produces the classification of survey questions in 7 hierarchical classes. On the other hand, a lack of tuning between objective parameters and perceptual responses is observed on applying MDS analysis to the ordination of the venues from a subjective assessment and a subjectiveobjective assessment. Finally, although the results show the mismatch between objective parameters and subjective responses, a model of subjective global evaluation of the acoustics of the room from data of three orthogonal acoustic parameters is implemented, revealing a reasonably good fit.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/VD7WLPS8/Giménez et al. - 2014 - Mismatches between objective parameters and measur.pdf}
}

@article{godinAestheticModificationRoom2019,
  title = {Aesthetic Modification of Room Impulse Responses for Interactive Auralization},
  author = {Godin, K. W. and Gamper, H. and Raghuvanshi, N.},
  year = {2019},
  pages = {8},
  journal = {AES International Conference on Immersive and Interactive Audio},
  abstract = {Interactive auralization workflows in games and virtual reality today employ manual markup coupled to designerspecified acoustic effects that lack spatial detail. Acoustic simulation can model such detail, yet is uncommon because realism often does not perfectly align with aesthetic goals. We show how to integrate realistic acoustic simulation while retaining designer control over aesthetics. Our method eliminates manual zone placement, provides spatially smooth transitions, and automates re-design for scene changes. It proceeds by computing perceptual parameters from simulated impulse responses, then applying transformations based on novel modification controls presented to the user. The result is an end-to-end physics-based auralization system with designer control. We present case studies that show the viability of such an approach.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/IKUGVSNC/Godin et al. - 2019 - Aesthetic modiﬁcation of room impulse responses fo.pdf}
}

@techreport{gotzCommonslopeModelingLate2022,
  type = {Preprint},
  title = {Common-Slope Modeling of Late Reverberation},
  author = {G{\"o}tz, G. and Schlecht, S. J. and Pulkki, V.},
  year = {2022},
  month = aug,
  doi = {10.36227/techrxiv.20482767.v1},
  urldate = {2022-12-05},
  abstract = {The decaying sound field in rooms is typically described in terms of energy decay functions (EDFs). Late reverberation can deviate considerably from the ideal diffuse field, for example, in scenes with multiple connected rooms or non-uniform absorption material distributions. This paper proposes the common-slope model of late reverberation. The model can be used to describe spatial and directional late reverberation variations as linear combinations of exponential decays with fixed decay times. Its fundamental idea is to determine a set of common decay times that is representative of multiple EDFs. Consequently, all spatial and directional EDF variations are described solely with amplitude changes of the respective decaying exponentials. After deriving the common-slope model, we explore different approaches for determining the common decay times for large EDF sets, whose EDFs describe different source-receiver configurations of the same environment. Among the presented approaches, the k-means clustering of decay times is the most general. Our evaluation shows that the common-slope model introduces only a small error between the modeled and the true EDF, although the common-slope model is considerably more compact than the traditional multi-exponential model. Due to its compactness, the common-slope model yields interpretable room acoustic analysis results. The common-slope model has potential applications in all fields relying on late reverberation models, such as source separation, dereverberation, echo cancellation, and parametric spatial audio rendering.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/N758TCY9/Götz et al. - 2022 - Common-slope modeling of late reverberation.pdf}
}

@article{gotzNeuralNetworkMultiexponential2022,
  title = {Neural Network for Multi-Exponential Sound Energy Decay Analysis},
  author = {G{\"o}tz, G. and F. P{\'e}rez, R. and Schlecht, S. J. and Pulkki, V.},
  year = {2022},
  month = aug,
  journal = {The Journal of the Acoustical Society of America},
  volume = {152},
  number = {2},
  pages = {942--953},
  issn = {0001-4966},
  doi = {10.1121/10.0013416},
  urldate = {2022-12-05},
  abstract = {An established model for sound energy decay functions (EDFs) is the superposition of multiple exponentials and a noise term. This work proposes a neural-network-based approach for estimating the model parameters from EDFs. The network is trained on synthetic EDFs and evaluated on two large datasets of over 20 000 EDF measurements conducted in various acoustic environments. The evaluation shows that the proposed neural network architecture robustly estimates the model parameters from large datasets of measured EDFs while being lightweight and computationally efficient. An implementation of the proposed neural network is publicly available.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/SA43M4CA/The_Availability_of_a_Hidden_Real_Reference_Affect.pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/VM3VT9ZX/Götz et al. - 2022 - Neural network for multi-exponential sound energy .pdf}
}

@article{griesingerPsychoacousticsApparentSource1997,
  title = {The {{Psychoacoustics}} of {{Apparent Source Width}}, {{Spaciousness}} and {{Envelopment}} in {{Performance Spaces}}},
  author = {Griesinger, D.},
  year = {1997},
  month = jul,
  journal = {Acta Acustica united with Acustica},
  volume = {83},
  pages = {721--731},
  abstract = {After a review of terminology, this paper presents an hypothesis for the psychoacoustic origins of the perception of spaciousness (assumed to be closely related to or identical to the perception of envelopment) and the apparent source width (ASW). The paper proposes that the apparent source width is broadened by reflected energy arriving during the rise time of musical sound segments (notes), while the perception of envelopment arises from reflected energy which arrives during sound segments or after they end. In addition we hypothesize that the perception of the most musically desirable form of spaciousness depends on the neural process which separates sound into a foreground stream (the sound segments themselves), and a background stream (the reverberation.) Our experiments suggest that the perception of the background stream is completely inhibited for at least 50 ms after the ends of sound segments, and the inhibition decreases to zero over an additional time period of 70 ms to 120 ms. Preliminary experiments find that when there are clear gaps between foreground sound events, the loudness of the background stream is absolute - independent of the loudness of the foreground stream.This view of the psychoacoustic origin of ASW and spaciousness suggests that ASW will not depend on the absolute loudness of the foreground segments, and that when sound segments have short rise times ASW will be narrow, even in a soundfield where the perception of spaciousness (and envelopment) is strong. The proposals also imply that the perception of spaciousness (and envelopment) will depend on 1. the absolute strength of the reverberant field at least 120 to 170 ms after the ends of sound events; 2. the spatial properties of the reverberant field in the same time period; and 3. the proportion of gaps in the musical source material which allows the background stream to be heard.Although there is currently insufficient experimental data to fully support these hypotheses, they make predictions which are both useful and easily tested.}
}

@article{habetsLateReverberantSpectral2009,
  title = {Late {{Reverberant Spectral Variance Estimation Based}} on a {{Statistical Model}}},
  author = {Habets, E. A. P. and Gannot, S. and Cohen, I.},
  year = {2009},
  journal = {IEEE SIGNAL PROCESSING LETTERS},
  volume = {16},
  number = {9},
  pages = {4},
  abstract = {In speech communication systems the received microphone signals are degraded by room reverberation and ambient noise that decrease the fidelity and intelligibility of the desired speaker. Reverberant speech can be separated into two components, viz. early speech and late reverberant speech. Recently, various algorithms have been developed to suppress late reverberant speech. One of the main challenges is to develop an estimator for the so-called late reverberant spectral variance (LRSV) which is required by most of these algorithms. In this letter a statistical reverberation model is proposed that takes the energy contribution of the direct-path into account. This model is then used to derive a more general LRSV estimator, which in a particular case reduces to an existing LRSV estimator. Experimental results show that the developed estimator is advantageous in case the source-microphone distance is smaller than the critical distance.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/FYUKCWBJ/Hearing An Introduction to Psychological and Physiological Acoustics, Sixth Edition (Stanley A. Gelfand) (z-lib.org).pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/XKLVWQPH/Habets et al. - 2009 - Late Reverberant Spectral Variance Estimation Base.pdf}
}

@book{havelockHandbookSignalProcessing2008,
  title = {Handbook of Signal Processing in Acoustics},
  editor = {Havelock, D. I. and Kuwano, S. and Vorl{\"a}nder, M.},
  year = {2008},
  publisher = {{Springer}},
  address = {{New York, NY}},
  isbn = {978-0-387-77698-9 978-0-387-30441-0},
  note = {isbn: 978-0-387-77698-9, 978-0-387-30441-0},
  langid = {english},
  lccn = {TA365 .H26 2008},
  keywords = {Acoustical engineering,Signal processing,Sound,Transmission},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/9AYWXJX9/Havelock et al. - 2008 - Handbook of signal processing in acoustics.pdf}
}

@article{hemphillMobilizationCalibrationHTC2020,
  title = {Mobilization and Calibration of the {{HTC VIVE}} for Virtual Reality Physical Therapy},
  author = {Hemphill, S. and Nguyen, A. and Rodriguez, S. T. and Menendez, M. and Wang, E. and Lawrence, K. and Caruso, T. J.},
  year = {2020},
  month = jan,
  journal = {Digital Health},
  volume = {6},
  issn = {2055-2076, 2055-2076},
  note = {doi: 10.1177/2055207620950929},
  doi = {10.1177/2055207620950929},
  urldate = {2023-03-09},
  abstract = {Methods: The VIVE was configured on a mobile cart. To validate the motion tracking software, the VIVE sensors (motion tracker, controller, headset) were mounted on a rigid linear track and driven through 10, one-meter translations in the X, Y, and Z axes. Results: The mean translational error for all three sensors was below 4.9 cm. While error is greater than that reported for research-grade systems, motion tracking software on the portable VIVE unit appears to be a valid means of tracking aggregate movement. Conclusion: Some therapy may require more precise measurements, however, the advantages of portability and accessibility to patients may outweigh the limitation of reduced precision.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/8THJAE2M/Hemphill et al. - 2020 - Mobilization and calibration of the HTC VIVE for v.pdf}
}

@article{hidakaNewDefinitionBoundary2007,
  title = {A New Definition of Boundary Point between Early Reflections and Late Reverberation in Room Impulse Responses},
  author = {Hidaka, T. and Yamada, Y. and Nakagawa, T.},
  year = {2007},
  month = jul,
  journal = {The Journal of the Acoustical Society of America},
  volume = {122},
  number = {1},
  pages = {326--332},
  issn = {0001-4966},
  doi = {10.1121/1.2743161},
  urldate = {2023-03-03},
  langid = {english}
}

@article{holdResynthesisSpatialRoom2022,
  title = {Resynthesis of {{Spatial Room Impulse Response Tails With Anisotropic Multi-Slope Decays}}},
  author = {Hold, C. and Mckenzie, T. and G{\"o}tz, G. and Schlecht, S. J. and Pulkki, V.},
  year = {2022},
  month = jul,
  journal = {Journal of the Audio Engineering Society},
  volume = {70},
  number = {6},
  pages = {526--538},
  issn = {15494950},
  doi = {10.17743/jaes.2022.0017},
  urldate = {2022-12-05},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/2G8XI6W9/Hold et al. - 2022 - Resynthesis of Spatial Room Impulse Response Tails.pdf}
}


@book{howardAcousticsPsychoacoustics2016,
  title = {Acoustics and Psychoacoustics},
  author = {Howard, D. M. and Angus, J.},
  year = {2016},
  edition = {5th edition},
  publisher = {{Routledge}},
  address = {{New York ; London}},
  isbn = {978-1-138-85987-6},
  lccn = {ML3805 .H77 2016},
  keywords = {Acoustics and physics,Music,Psychoacoustics}
}

@book{huangHumanFactorsAugmented2013,
  title = {Human {{Factors}} in {{Augmented Reality Environments}}},
  editor = {Huang, W. and Alem, L. and Livingston, M. A.},
  year = {2013},
  publisher = {{Springer New York}},
  address = {{New York, NY}},
  doi = {10.1007/978-1-4614-4205-9},
  urldate = {2022-08-18},
  isbn = {978-1-4614-4204-2 978-1-4614-4205-9},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/J243JHY2/Huang et al. - 2013 - Human Factors in Augmented Reality Environments.pdf}
}


@techreport{IEC61260ELECTROACOUSTICS,
address = {Geneva, CH},
type = {Standard},
title = {{{{Electroacoustics}} - {{Octave-band and Fractional-Octave-band Filters}}} -- {Part} 1: {Specifications}},
shorttitle = {IEC 61260-1:2014},
number = {IEC 61260-1:2014},
language = {en},
institution = {International Electrotechnical Commission},
author = {{IEC}},
month = {Feb.},
year = {2014}
}



@inproceedings{ijsselsteijnPresenceConceptDeterminants2000,
  title = {Presence: Concept, Determinants, and Measurement},
  shorttitle = {Presence},
  booktitle = {Electronic {{Imaging}}},
  author = {IJsselsteijn, Wijnand A. and {de Ridder}, Huib and Freeman, Jonathan and Avons, Steve E.},
  editor = {Rogowitz, Bernice E. and Pappas, Thrasyvoulos N.},
  year = {2000},
  month = jun,
  pages = {520--529},
  address = {{San Jose, CA}},
  doi = {10.1117/12.387188},
  note = {doi: 10.1117/12.387188},
  urldate = {2022-08-28},
  abstract = {The concept of presence, i.e. the sensation of `being there' in a mediated environment, has received substantial attention from the virtual reality community, and is becoming increasingly relevant both to broadcasters and display developers. Although research into presence is still at an early stage of development, there is a consensus that presence has multiple determinants. To identify and test which parameters affect presence, a reliable, robust and valid means of measuring presence is required. In this paper, we describe the categories of factors thought to have an impact on presence. Furthermore, we present an overview of various approaches taken to measuring presence, which can be divided into two general categories: subjective measures and objective corroborative measures. Since presence is a subjective experience, the most direct way of assessment is through users' subjective report. This approach has serious limitations however, and should be used judiciously. Objective measures, such as postural, physiological or social responses to media, can be used to corroborate subjective measures, thereby overcoming some of their limitations. At present, the most promising direction for presence measurement is to develop and use an aggregate measure of presence that is comprised of both subjective and objective components, tailored to the specific medium under study.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/2IK7UE5I/IJsselsteijn et al. - 2000 - Presence concept, determinants, and measurement.pdf}
}

@book{jekoschVoiceSpeechQuality2005,
  title = {Voice and {{Speech Quality Perception}}: {{Assessment}} and {{Evaluation}}},
  shorttitle = {Voice and {{Speech Quality Perception}}},
  author = {Jekosch, Ute},
  year = {2005},
  month = dec,
  publisher = {{Springer Berlin, Heidelberg}},
  abstract = {Foundations of Voice and Speech Quality Perception starts out with the fundamental question of: "How do listeners perceive voice and speech quality and how can these processes be modeled?" Any quantitative answers require measurements. This is natural for physical quantities but harder to imagine for perceptual measurands. This book approaches the problem by actually identifying major perceptual dimensions of voice and speech quality perception, defining units wherever possible and offering paradigms to position these dimensions into a structural skeleton of perceptual speech and voice quality. The emphasis is placed on voice and speech quality assessment of systems in artificial scenarios. Many scientific fields are involved. This book bridges the gap between two quite diverse fields, engineering and humanities, and establishes the new research area of Voice and Speech Quality Perception.},
  googlebooks = {8OM7CmWQYAcC},
  isbn = {978-3-540-28860-2},
  note = {isbn: 978-3-540-28860-2},
  langid = {english},
  keywords = {Computers / Artificial Intelligence / Natural Language Processing,Computers / Speech \& Audio Processing,Computers / User Interfaces,Science / Acoustics \& Sound,Science / Physics / General,Science / Waves \& Wave Mechanics,Technology \& Engineering / Electronics / General,Technology \& Engineering / Imaging Systems}
}

@article{jeongKurtosisRoomImpulse2016,
  title = {Kurtosis of Room Impulse Responses as a Diffuseness Measure for Reverberation Chambers},
  author = {Jeong, Cheol-Ho},
  year = {2016},
  month = may,
  journal = {The Journal of the Acoustical Society of America},
  volume = {139},
  number = {5},
  pages = {2833--2841},
  issn = {0001-4966},
  doi = {10.1121/1.4949365},
  urldate = {2022-11-24},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/MWBZYY5N/Jeong - 2016 - Kurtosis of room impulse responses as a diffusenes.pdf}
}


@article{kapralosAuditoryPerceptionSpatial,
  title = {Auditory {{Perception}} and {{Spatial}} ({{3D}}) {{Auditory Systems4}}},
  author = {Kapralos, B and Jenkin, M and Milios, E},
  abstract = {In order to enable the user of a virtual reality system to be fully immersed in the virtual environment, the user must be presented with believable sensory input. Although the majority of virtual environments place the emphasis on visual cues, replicating the complex interactions of sound within an environment will benefit the level of immersion and hence the user's sense of presence. Three dimensional (spatial) sound systems allow a listener to perceive the position of sound sources, and the effect of the interaction of sound sources with the acoustic structure of the environment. This paper reviews the relevant biological and technical literature relevant to the generation of accurate acoustic displays for virtual environments, beginning with an introduction to the process of auditory perception in humans. This paper then critically examines common methods and techniques that have been used in the past as well as methods and techniques which are currently being used to generate spatial sound. In the process of doing so, the limitations, drawbacks, advantages and disadvantages associated with these techniques are also presented.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/8GBZCPP8/Kapralos et al. - Auditory Perception and Spatial (3D) Auditory Syst.pdf}
}
@Conference{Sloma2019,
  author    = {Sloma, Ulrike and Klein, Florian and Werner, Stephan and Pappachan Kannookadan, Tyson},
  title     = {Synthesis of Binaural Room Impulse Responses for Different Listening Positions Considering the Source Directivity},
  booktitle = {147th AES Convention, New York, NY, USA, 2019},
  year      = {2019},
  address   = {},
  month     = {Oct},
}
@Inproceedings{Poerschi2017,
  author    = {Pörschmann, Christoph and Stade, Philipp and Arend, Johannes M},
  title     = {Binauralization of omnidirectional room impulse responses-algorithm and technical evaluation},
  booktitle = {Proceedings 20th DAFx},
  year      = {2017},
  pages     = {345--352},
  address   = {Edinburgh, UK, 2017},
  month     = {Sep},
}

@Article{BRINKMANN:RoundRobin:2019,
  author    = {Brinkmann, Fabian and Asp{\"o}ck, Lukas and Ackermann, David and Lepa, Steffen and Vorl{\"a}nder, Michael and Weinzierl, Stefan},
  title     = {A round robin on room acoustical simulation and auralization},
  journal   = {J. Acoust. Soc. Am.},
  year      = {2019},
  volume    = {145},
  number    = {4},
  pages     = {2746--2760},
  doi       = {10.1121/1.5096178},
}
@Book{Blauert1997,
  author    = {Blauert, Jens},
  title     = {Spatial hearing: the psychophysics of human sound localization},
  isbn={9780262024136},
  publisher = {MIT press},
  year      = {1997},
}

@article{Pastore2015,
    author = {Pastore, M. Torben and Braasch, Jonas},
    title = "{The precedence effect with increased lag level}",
    journal = {The Journal of the Acoustical Society of America},
    volume = {138},
    number = {4},
    pages = {2079-2089},
    year = {2015},
    month = {10},
    abstract = "{When a pair of sounds arrive from different directions with a sufficiently short delay between them, listeners hear a perceptually fused image with a perceived location that is dominated by the first arriving sound. This is called the precedence effect. To test the limits of this phenomenon, 200-ms noise stimuli were presented over headphones to model a temporally overlapping direct sound (lead) with a single reflection (lag) at inter-stimulus intervals (ISIs) of 0–5 ms. Lag intensity exceeded that of the lead by 0–10 dB. Results for 16 listeners show that lateralization shifted from the position of the lead towards the lag as lag level increased. Response variability also increased with lag level. An oscillatory pattern emerged across ISIs as lag level increased, to a degree that varied greatly between listeners. Analysis of modeled binaural cues suggests that these oscillatory patterns are correlated with ILDs produced by the physical interference of lead and lag during the ongoing portion of the stimulus, especially in the 764-Hz frequency band. Different listeners apparently weighted cues from the onset versus ongoing portions of the stimulus differently, as evidenced by the varying degree of influence the ongoing ILD cues had on listeners' perceived lateralization.}",
    issn = {0001-4966},
    doi = {10.1121/1.4929940},
    url = {https://doi.org/10.1121/1.4929940},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/138/4/2079/13447148/2079\_1\_online.pdf},
}





@article{Rakerd1985LocalizationOS,
  title={Localization of sound in rooms, II: The effects of a single reflecting surface.},
  author={Brad Rakerd and William Hartmann},
  journal={The Journal of the Acoustical Society of America},
  year={1985},
  volume={78 2},
  pages={
          524-33
        }
}

@phdthesis{kleinAuditiveAdaptationsprozesseIm2021,
  title = {Auditive {{Adaptationsprozesse}} Im {{Kontext}} R\"aumlicher {{Audiowiedergabesysteme}}},
  author = {Klein, Florian},
  year = {2021},
  month = nov,
  doi = {10.22032/DBT.50107},
  urldate = {2022-08-24},
  abstract = {The goal of technical evolutions in the context of entertainment electronics is to improve the user experience by providing visuals and acoustics in the best possible way. With modern virtual and augmented reality devices and applications the goal of a reproduction indistinguishable from reality became more tangible. When the listener is no longer able to distinguish artificial sound sources from real ones the term auditory illusion is used. In order to achieve such illusions different technical challenges need to be mastered. But the assumption that the exact replica of the ear signals lead to the same perceptions as in the corresponding real-life situation is not correct. Fundamental mechanisms of human perception such as the integration of cues from different modalities and the dependency on expectations and experience add another layer of complexity. These expectations can change depending on prior sound exposure. In the context of spatial hearing this means that listeners are probably able to learn how to interpret spatial cues. Such mechanisms and their effect on the perceived quality of spatial sound reproduction systems are the scope of this work. Perceptual studies investigate the learning of spatial localization cues and adaptation mechanisms related to room acoustic perception. Quality deficits due to mismatched ear signals are measured and it is shown how quality ratings can change depending on training. The results suggest, that learning and adaptation processes are a key factor for the establishment of an auditory illusion. The practical relevance of such effects and their underlying principles are discussed.},
  collaborator = {{Th{\"u}ringer Universit{\"a}ts- Und Landesbibliothek Jena} and Brandenburg, Karlheinz and Seeber, Bernhard and P{\"o}rschmann, Christoph},
  copyright = {all rights reserved},
  langid = {english},
  school = {TU Ilmenau},
  keywords = {621.3,Binaurales Hören,Lernendes System,Raumakustik,Unterhaltungselektronik,Wiedergabetechnik},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/75BVLCJ8/Klein - 2021 - Auditive Adaptationsprozesse im Kontext räumlicher.pdf}
}

@article{lindau2012perceptual,
  title={Perceptual evaluation of model-and signal-based predictors of the mixing time in binaural room impulse responses},
  author={Lindau, A. and Kosanke, L. and Weinzierl, S.},
  journal={Journal of the Audio Engineering Society},
  volume={60},
  number={11},
  pages={887--898},
  year={2012},
  publisher={Audio Engineering Society}
}


@article{Henning2021,
    author = {Steffens, Henning and van de Par, Steven and Ewert, Stephan D.},
    title = "{The role of early and late reflections on perception of source orientation}",
    journal = {The Journal of the Acoustical Society of America},
    volume = {149},
    number = {4},
    pages = {2255-2269},
    year = {2021},
    month = {04},
    abstract = "{Sound radiation of most natural sources, like human speakers or musical instruments, typically exhibits a spatial directivity pattern. This directivity contributes to the perception of sound sources in rooms, affecting the spatial energy distribution of early reflections and late diffuse reverberation. Thus, for convincing sound field reproduction and acoustics simulation, source directivity has to be considered. Whereas perceptual effects of directivity, such as source-orientation-dependent coloration, appear relevant for the direct sound and individual early reflections, it is unclear how spectral and spatial cues interact for later reflections. Better knowledge of the perceptual relevance of source orientation cues might help to simplify the acoustics simulation. Here, it is assessed as to what extent directivity of a human speaker should be simulated for early reflections and diffuse reverberation. The computationally efficient hybrid approach to simulate and auralize binaural room impulse responses [Wendt et al., J. Audio Eng. Soc. 62, 11 (2014)] was extended to simulate source directivity. Two psychoacoustic experiments assessed the listeners' ability to distinguish between different virtual source orientations when the frequency-dependent spatial directivity pattern of the source was approximated by a direction-independent average filter for different higher reflection orders. The results indicate that it is sufficient to simulate effects of source directivity in the first-order reflections.}",
    issn = {0001-4966},
    doi = {10.1121/10.0003823},
    url = {https://doi.org/10.1121/10.0003823},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/149/4/2255/13039241/2255\_1\_online.pdf},
}





@Phdthesis{KuhnRahloff2012,
  author    = {Kuhn-Rahloff, C.},
  title     = {Realit{\"a}tstreue, {N}at{\"u}rlichkeit, {P}lausibilit{\"a}t: {P}erzeptive {B}eurteilungen in der {E}lektroakustik},
  school    = {TU Berlin, Germany},
  year      = {2012},
}
@article{kleinAuditoryAdaptationNonIndividual2016,
  title = {Auditory {{Adaptation}} to {{Non-Individual HRTF Cues}} in {{Binaural Audio Reproduction}}},
  author = {Klein, Florian and Werner, Stephan},
  year = {2016},
  month = feb,
  journal = {Journal of the Audio Engineering Society},
  volume = {64},
  pages = {45--54},
  doi = {10.17743/jaes.2015.0092},
  note = {doi: 10.17743/jaes.2015.0092},
  abstract = {It is well known that the human perceptual system can adapt by changing its processing properties when exposed to feedback and context. The brain is not a fixed stimulus-response system. This report investigates auditory adaptation processes in spatial listening tasks for people with normal hearing ability. The auditory adaptation process to altered auditory cues of thirteen participants was monitored and compared to their normal hearing listening performance. Binaural room impulse responses were measured for each participant and for an artificial head. Listeners were trained to non-individual HRTF cues in an audiovisual training task. Ten out of thirteen listeners showed significant improvement in their ability to localize sound sources varying in elevation on the median plane after training. Two of these listeners performed better with trained artificial binaural room impulse responses than with their individual measured room impulse responses. Listening tests show that audiovisual training with artificial binaural room impulse responses decreases localization error significantly in the median plane.}
}


@article{kleinAuditoryAdaptationReal,
  title = {Auditory Adaptation in Real and Virtual Rooms},
  author = {Klein, Florian and Werner, Stephan and Go, Georg},
  pages = {8},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/5U9Y7BKS/Klein et al. - Auditory adaptation in real and virtual rooms.pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/8ADQBJ5U/On_the_authenticity_of_individual_dynamic_binaural.pdf}
}

@inproceedings{klein2019auditory,
  title={Auditory adaptation in real and virtual rooms},
  author={Klein, F. and Werner, S. and G{\"o}tz, G. and Brandenburg, K.},
  booktitle={Proceedings of the International Symposium on Auditory and Audiological Research},
  volume={7},
  pages={341--348},
  year={2019}
}

@inproceedings{kleinDeterminingThresholdsRoom2021,
  title = {Towards Determining Thresholds for Room Divergence: {{A}} Pilot Study on Detection Thresholds},
  shorttitle = {Towards Determining Thresholds for Room Divergence},
  booktitle = {2021 {{Immersive}} and {{3D Audio}}: From {{Architecture}} to {{Automotive}} ({{I3DA}})},
  author = {Klein, Florian and Gari, Sebastia V. Amengual and Arend, Johannes M. and Robinson, Philip W.},
  year = {2021},
  month = sep,
  pages = {1--7},
  publisher = {{IEEE}},
  address = {{Bologna, Italy}},
  doi = {10.1109/I3DA48870.2021.9610876},
  urldate = {2022-08-10},
  abstract = {In binaural rendering, the room divergence effect refers to the decrease in perceived externalization due to a mismatch between the room acoustics of the virtual sounds and those of the listening space. However, it is currently unknown which specific acoustic differences cause this effect. In this work, we present a pilot study to determine detection thresholds between sound sources recorded under different acoustic conditions in a variable acoustics room. These results are intended to predict situations where divergence effects can be expected. The participants had to perform a triangle test where they could listen to three sound sources placed at different positions in the room. The test design was motivated by the fact that sound sources are not placed at the same position in real acoustic scenes. One sound source was recorded under different acoustic conditions than the other two, and the task for the participant was to detect the differing source. The test was conducted in the measured room using 3 DoF binaural reproduction and using a virtual reality (VR) headset to display a visual 360 capture of the room enabling the subjects to see the positions of the sources in the room. Detection rates are signal-dependent and increase with differences in reverberation time (RT). For the most critical signal in the test (castanets), an RT difference of 8\% was detectable, while the difference was 15\% across all conditions. Furthermore, we discuss the influence of sound source distance and absorption configuration (symmetric or asymmetric) on detection thresholds.},
  isbn = {978-1-66540-998-8},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/CVE862DU/Klein et al. - 2021 - Towards determining thresholds for room divergence.pdf}
}

@article{kleinInfluencesTrainingExternalization2017,
  title = {Influences of {{Training}} on {{Externalization}} of {{Binaural Synthesis}} in {{Situations}} of {{Room Divergence}}},
  author = {Klein, Florian and Werner, Stephan and Mayenfels, Thomas},
  year = {2017},
  month = mar,
  journal = {Journal of the Audio Engineering Society},
  volume = {65},
  number = {3},
  pages = {178--187},
  issn = {15494950},
  doi = {10.17743/jaes.2016.0072},
  urldate = {2022-08-22},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/XVJL7WPL/Klein et al. - 2017 - Influences of Training on Externalization of Binau.pdf}
}

@article{klockgetherJustNoticeableDifferences2016,
  title = {Just Noticeable Differences of Spatial Cues in Echoic and Anechoic Acoustical Environments},
  author = {Klockgether, Stefan and {van de Par}, Steven},
  year = {2016},
  month = oct,
  journal = {The Journal of the Acoustical Society of America},
  volume = {140},
  number = {4},
  pages = {EL352},
  issn = {1520-8524},
  doi = {10.1121/1.4964844},
  note = {doi: 10.1121/1.4964844},
  abstract = {The perceptual limits for detecting changes in binaural cues also define the boundaries for the perception of differences in spatial impression. This study reports just noticeable differences for interaural time delays (ITDs) and interaural level differences (ILDs) of the early part and for the interaural cross-correlation (IACC) of the early and diffuse part of binaural room impulse responses. The results show that ITDs only allow a high accuracy in localization in anechoic environments, whereas ILDs show a higher robustness against reverberation. Subjects are rather insensitive to changes in IACC, only changes that bring the IACC close to one are detectable.},
  langid = {english},
  pmid = {27794310},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/F2MRJYBS/Klockgether and van de Par - 2016 - Just noticeable differences of spatial cues in ech.pdf}
}

@article{klumppMeasurementsInterauralTime1956,
  title = {Some Measurements of Interaural Time Difference Thresholds},
  author = {Klumpp, R. G. and Eady, H. R.},
  year = {1956},
  journal = {Journal of the Acoustical Society of America},
  volume = {28},
  pages = {859--860},
  publisher = {{Acoustical Society of American}},
  address = {{US}},
  issn = {0001-4966},
  doi = {10.1121/1.1908493},
  note = {doi: 10.1121/1.1908493},
  abstract = {Measurements of the threshold of detection of an interaural time difference from a zero reference interaural time difference were obtained for a wide range of signals. The threshold increased from 9-10 micro-seconds for a broad-band noise to 62 micro-seconds for a narrow-band high frequency noise. Thresholds were most acute with a zero reference interaural time difference. The threshold increased at the rate of about 1 microsecond for every 20 microseconds of displacement of the reference standard. (PsycINFO Database Record (c) 2016 APA, all rights reserved)},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/SVVHNM9Z/1957-07185-001.html}
}

@book{kuttruffRoomAcoustics2017,
  title = {Room Acoustics},
  author = {Kuttruff, Heinrich},
  year = {2017},
  edition = {6th},
  publisher = {{CRC Press/Taylor \& Francis Group}},
  address = {{Boca Raton}},
  isbn = {978-1-4822-6043-4},
  note = {isbn: 978-1-4822-6043-4},
  langid = {english},
  lccn = {NA2800 .K87 2017},
  keywords = {Architectural acoustics},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/2MS27VVI/Kuttruff - 2017 - Room acoustics.pdf}
}

@article{larsenMinimumAudibleDifference2008,
  title = {On the Minimum Audible Difference in Direct-to-Reverberant Energy Ratio},
  author = {Larsen, E. and Iyer, N. and Lansing, C. R. and Feng, A. S.},
  year = {2008},
  month = jul,
  journal = {The Journal of the Acoustical Society of America},
  volume = {124},
  number = {1},
  pages = {450--461},
  issn = {0001-4966},
  doi = {10.1121/1.2936368},
  note = {doi: 10.1121/1.2936368},
  urldate = {2023-03-07},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/UA5LIBZE/Larsen et al. - 2008 - On the minimum audible difference in direct-to-rev.pdf}
}

@article{latoschikCoherencePlausibilityNot,
  title = {Coherence and {{Plausibility}}, Not {{Presence}}?! {{Pivotal Conditions}} for {{XR Experiences}} and {{Effects}}, a {{Novel Model}}},
  author = {Latoschik, Marc Erich and Wienrich, Carolin},
  abstract = {Presence often is considered the most important quale describing the subjective feeling of being in a computer-generated (virtual) or computer-mediated environment. The identification and separation of two orthogonal presence components, i.e., the place illusion and the plausibility illusion, has been an accepted theoretical model describing Virtual Reality (VR) experiences for some time. In this model, immersion is a proposed contributing factor to the place illusion. Lately, copresence and social presence illusions have extended this model, and coherence was proposed as a contributing factor to the plausibility illusion. Such factors strive to identify (objectively) measurable characteristics of an experience, e.g., systems properties that allow controlled manipulations of VR experiences. This perspective article challenges this presence-oriented VR theory. First, we argue that a place illusion cannot be the major construct to describe the much wider scope of Virtual, Augmented, and Mixed Reality (VR, AR, MR: or XR for short). Second, we argue that there is no plausibility illusion but merely plausibility, and we derive the place illusion as a consequence of a plausible generation of spatial cues, and similarly for all of the current model's so-defined illusions. Finally, we propose coherence and plausibility to become the central essential conditions in a novel theoretical model describing XR experiences and effects.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/KQFS2MKX/Latoschik and Wienrich - Coherence and Plausibility, not Presence! Pivotal.pdf}
}

@incollection{letowskiLocalizationErrorAccuracy2011,
  title = {Localization {{Error}}: {{Accuracy}} and {{Precision}} of {{Auditory Localization}}},
  shorttitle = {Localization {{Error}}},
  booktitle = {Advances in {{Sound Localization}}},
  author = {Letowski, Tomasz and Letowski, Szymon},
  editor = {Strumillo, Pawel},
  year = {2011},
  month = apr,
  publisher = {{InTech}},
  doi = {10.5772/15652},
  urldate = {2023-02-04},
  isbn = {978-953-307-224-1},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/W5I6T9KK/Letowski and Letowski - 2011 - Localization Error Accuracy and Precision of Audi.pdf}
}

@Article{liInfluenceBinauralRoom2021,
AUTHOR = {Li, Song and Schlieper, Roman and Tobbala, Aly and Peissig, Jürgen},
TITLE = {The Influence of Binaural Room Impulse Responses on Externalization in Virtual Reality Scenarios},
JOURNAL = {Applied Sciences},
VOLUME = {11},
YEAR = {2021},
NUMBER = {21},
ARTICLE-NUMBER = {10198},
URL = {https://www.mdpi.com/2076-3417/11/21/10198},
note = {doi: 10.3390/app112110198},
ISSN = {2076-3417},
ABSTRACT = {A headphone-based virtual sound image can not be perceived as perfectly externalized if the acoustic of the synthesized room does not match that of the real listening environment. This effect has been well explored and is known as the room divergence effect (RDE). The RDE is important for perceived externalization of virtual sounds if listeners are aware of the room-related auditory information provided by the listening environment. In the case of virtual reality (VR) applications, users get a visual impression of the virtual room, but may not be aware of the auditory information of this room. It is unknown whether the acoustic congruence between the synthesized (binaurally rendered) room and the visual-only virtual listening environment is important for externalization. VR-based psychoacoustic experiments were performed and the results reveal that perceived externalization of virtual sounds depends on listeners’ expectations of the acoustic of the visual-only virtual room. The virtual sound images can be perceived as externalized, although there is an acoustic divergence between the binaurally synthesized room and the visual-only virtual listening environment. However, the “correct” room information in binaural sounds may lead to degraded externalization if the acoustic properties of the room do not match listeners’ expectations.},
DOI = {10.3390/app112110198}
}


@article{lindauAssessingPlausibilityVirtual2012,
  title = {Assessing the {{Plausibility}} of {{Virtual Acoustic Environments}}},
  author = {Lindau, A. and Weinzierl, S.},
  year = {2012},
  month = sep,
  journal = {Acta Acustica united with Acustica},
  volume = {98},
  number = {5},
  pages = {804--810},
  issn = {16101928},
  doi = {10.3813/AAA.918562},
  note = {doi: 10.3813/AAA.918562},
  urldate = {2023-01-18},
  abstract = {Aiming at the perceptual evaluation of virtual acoustic environments (VAEs), `plausibility' is introduced as a quality criterion that can be of value for many applications of virtual realities. We suggest a definition as well as an experimental operationalization for plausibility, referring to the perceived agreement with the listener's expectation towards an equivalent real acoustic event. A listening test methodology for the criterion-free assessment of the deviation from this non-explicit, inner reference is proposed. It requires the rating of corresponding real and simulated stimuli in a Yes/No test paradigm, and the analysis of the results according to signal detection theory. The specification of minimum effect hypotheses allows the testing of plausibility with any desired strictness. The approach is demonstrated with the perceptual evaluation of a system for dynamic binaural synthesis in two different development stages.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/BUE4KLAH/Lindau and Weinzierl - 2012 - Assessing the Plausibility of Virtual Acoustic Env.pdf}
}

@conference{lindauPerceptualEvaluationPhysical2010,
		title = {Perceptual Evaluation of Physical Predictors of the Mixing Time in Binaural Room Impulse Responses},
		author = {Lindau, Alexander and Kosanke, Linda and Weinzierl, Stefan},
		booktitle = {Audio Engineering Society Convention 128},
		month = {May},
		year = {2010},
            note = {Paper 8089},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=15386}
		}

@conference{meesawatTimeWhenReverberation2003,
		title = {The Time When the Reverberation Tail in a Binaural Room Impulse Response Begins},
		author = {Meesawat, Kittiphong and Hammershoi, Dorte},
		booktitle = {Audio Engineering Society Convention 115},
		month = {Oct},
		year = {2003},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=12346}
		}

@article{meiRobustnessRoomImpulse,
  title = {On the {{Robustness}} of {{Room Impulse Response Reshaping}}},
  author = {Mei, Tiemin and Mertins, Alfred},
  pages = {4},
  abstract = {In room impulse response (RIR) equalization and reshaping, one of the difficulties is the spatial robustness, because RIRs are very sensitive to the movements of both the signal source and the receiver. For example, the reshaping filter designed for one pair of loudspeaker/receiver or source/microphone positions will be ineffective for another pair. In this paper, we concentrate on loudspreaker/receiver pairs and propose a novel approach in which we use multiple prefilters to reshape simultaneously the RIR samples in a given area of interest (listening area). According to the RIR sampling principle, we prove statistically that the listening area will be reshaped if only the RIR samples in this area are reshaped. In simulations, we show that the proposed approach is valid.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/3MWLYKT4/The_Availability_of_a_Hidden_Real_Reference_Affect.pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/HM48K2MY/Mei and Mertins - On the Robustness of Room Impulse Response Reshapi.pdf}
}

@article{melchiorVisualizationModificationRoom,
  title = {On the Visualization and Modification of Room Impulse Responses for Sound Design},
  author = {Melchior, F and Vries, D De},
  pages = {2},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/GNMPSQ26/Melchior and Vries - On the visualization and modification of room impu.pdf}
}


@conference{mendoncaADAPTATIONNONINDIVIDUALISEDHRTF2012,
		title = {On the Adaptation to Non-Individualized HRTF Auralizations: A Longitudinal Study},
		author = {Mendonça, Catarina and Santos, Jorge A. and Campos, Guilherme and Dias, Paulo and Vieira, José},
		booktitle = {Audio Engineering Society Conference: 45th International Conference: Applications of Time-Frequency Processing in Audio},
		month = {Mar},
		year = {2012},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=16181}
		}

@inproceedings{TransferPlausibilityBinauralRendering2022,
title = {Transfer-Plausibility of Binaural Rendering with Different Real-World References},
abstract = {For the evaluation of virtual acoustics for mixed realities, we distinguish between the paradigms {"}authenticity{"}, {"}plausibility{"} and {"}transfer-plausibility{"}. In the case of authenticity, discrimination tasks between real sound sources and virtual renderings presented over headphones are performed, whereas in case of a plausibility experiment, listeners need to rely only on their expectation of a sound when listening to the rendering, without the presence of an explicit reference. In the case of transfer-plausibility, however, different real sources are active alongside virtual sources, potentially in different spatial locations, leading to a certain degree of comparability. This resembles the case of forthcoming augmented reality systems. Here, we show an experiment, which assesses the transfer-plausibility of rendered speech sources in a variable acoustic environment. We demonstrate the influence of the similarity between real and virtual source material and their spatial location on the transfer-plausibility of measurement-based headphone rendering.},
author = {N. Meyer-Kahlen and Gar{\'i}, {S. V. A.} and T. McKenzie and S. Schlecht and T. Lokki},
year = {2022},
month = {mar},
day = {24},
language = {English},
booktitle = {Fortschritte der Akustik - DAGA 2022},
publisher = {German Acoustical Society (DEGA)},
}
@phdthesis{NilsMeyerKahlen,
    author = {N. Meyer-Kahlen},
    title = {Transfer-Plausible Acoustics for Augmented Reality},
    school = {Aalto University},
    year = 2024
}

@article{millsLateralizationHighFrequency1960,
  title = {Lateralization of {{High}}-{{Frequency Tones}}},
  author = {Mills, A. W.},
  year = {1960},
  month = jan,
  journal = {The Journal of the Acoustical Society of America},
  volume = {32},
  number = {1},
  pages = {132--134},
  issn = {0001-4966},
  doi = {10.1121/1.1907864},
  note = {doi: 10.1121/1.1907864},
  urldate = {2023-03-24},
  abstract = {Thresholds for interaural difference between the intensities of dichotic tone pulses were measured on five subjects by the method of constant stimuli, at frequencies between 250 and 10 000 cps and at a sensation level of 50 db. The just noticeable dichotic difference in intensity is about 1 db at 1000 cps, a little smaller at lower frequencies, and still smaller (0.5 db) at higher frequencies. This function is compared with the interaural difference in intensity produced by the just noticeable deviation from the median plane of an actual source of tone pulses. At low frequencies, where phase or time differences are generally considered more important than intensity differences for auditory localization, these two functions differ greatly. At frequencies between 1500 and 6000 cps, the threshold for a dichotic difference in intensity matches the interaural difference in intensity that is produced by the just noticeable deviation from the median plane of an actual source. The relation between the discriminat...},
  langid = {english}
}

@article{miPerceptualSimilaritiesArtificial2023,
  title = {Perceptual {{Similarities}} between {{Artificial Reverberation Algorithms}} and {{Real Reverberation}}},
  author = {Mi, Huan and Kearney, Gavin and Daffern, Helena},
  year = {2023},
  month = jan,
  journal = {Applied Sciences},
  volume = {13},
  number = {2},
  pages = {840},
  issn = {2076-3417},
  doi = {10.3390/app13020840},
  urldate = {2023-01-18},
  abstract = {This paper presents a study evaluating the perceptual similarity between artificial reverberation algorithms and acoustic measurements. An online headphone-based listening test was conducted and data were collected from 20 expert assessors. Seven reverberation algorithms were tested in the listening test, including the Dattorro, Directional Feedback Delay Network (DFDN), Feedback Delay Network (FDN), Gardner, Moorer, and Schroeder reverberation algorithms. A new Hybrid Moorer\textendash Schroeder (HMS) reverberation algorithm was included as well. A solo cello piece, male speech, female singing, and a drumbeat were rendered with the seven reverberation algorithms in three different reverberation times (0.266 s, 0.95 s and 2.34 s) as the test conditions. The test was conducted online and based on the Multiple Stimuli with Hidden Reference and Anchor (MUSHRA) paradigm. The reference conditions consisted of the same audio samples convolved with measured binaural room impulse responses (BRIRs) with the same three reverberation times. The anchor was dual-mono 3.5 kHz low pass filtered audio. The similarity between the test audio and the reference audio was scored on a scale of zero to a hundred. Statistical analysis of the results shows that the Gardner and HMS reverberation algorithms are good candidates for exploration of artificial reverberation in Augmented Reality (AR) scenarios in future research.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/VHGFM6RE/Mi et al. - 2023 - Perceptual Similarities between Artificial Reverbe.pdf}
}

@article{mollerQualityExperienceTerminology2014,
  title = {Quality of {{Experience}}: {{Terminology}}, {{Methods}} and {{Applications}}},
  shorttitle = {Quality of {{Experience}}},
  author = {M{\"o}ller, Sebastian and Raake, Alexander},
  year = {2014},
  month = jan,
  journal = {PIK - Praxis der Informationsverarbeitung und Kommunikation},
  volume = {37},
  number = {4},
  issn = {1865-8342, 0930-5157},
  doi = {10.1515/pik-2014-0027},
  urldate = {2023-03-08},
  abstract = {In this paper, we discuss how the concept of Quality of Experience (QoE) has evolved during the last two decades, resulting in a need for a common terminology, as well as the need for applying the identified concepts to new applications and services. Regarding the first issue, we review the development of definitions of quality and QoE, and summarize the latest status which resulted in the `Qualinet White Paper on Definitions of Quality of Experience', the history of which will be briefly reviewed, pointing out recent further developments. Regarding the second issue, we summarize methods and applications which have been collected in a recently edited book following the Qualinet White Paper, and which the present paper is largely based on.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/SCXWK9TS/Möller and Raake - 2014 - Quality of Experience Terminology, Methods and Ap.pdf}
}

@book{mooreHearing1995,
  title = {Hearing},
  editor = {Moore, B. C. J.},
  year = {1995},
  series = {Handbook of Perception and Cognition (2nd Ed.)},
  publisher = {{Academic Press}},
  address = {{San Diego}},
  isbn = {978-0-12-505626-7},
  note = {isbn: 978-0-12-505626-7},
  langid = {english},
  lccn = {BF251 .M65 1995},
  keywords = {Auditory perception,Hearing,Psychoacoustics},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/H2AHENLZ/1.4949365.pdf;/home/MR/snap/zotero-snap/common/Zotero/storage/YW4YDPGZ/Moore - 1995 - Hearing.pdf}
}

@book{neidhardtannikaBRIRDataSet2020,
  author       = {Neidhardt, A. and
                  Zerlik, A.-M. and
                  Kamandi, S.},
  title        = {{BRIR data set for interactive listener translation 
                   in two rooms}},
  month        = jul,
  year         = 2020,
  note         = {{More details about the measurement are provided in 
                   the following publication: Neidhardt, A., "Data
                   set: BRIRs for position-dynamic binaural synthesis
                   measured in two rooms",  In: Proceedings of 5th
                   International Conference on Spatial Audio (ICSA),
                   Ilmenau, Germany, Sept. 2019, doi: 10.5281/zenodo.3457782.}},
  publisher    = {Zenodo},
  version      = {1.0},
  doi          = {10.5281/zenodo.3457782},
  url          = {https://doi.org/10.5281/zenodo.3457782}
}

@article{neidhardtAvailabilityHiddenReal2021,
  title = {The {{Availability}} of a {{Hidden Real Reference Affects}} the {{Plausibility}} of {{Position-Dynamic Auditory AR}}},
  author = {Neidhardt, Annika and Zerlik, Anna Maria},
  year = {2021},
  month = sep,
  journal = {Frontiers in Virtual Reality},
  volume = {2},
  pages = {678875},
  issn = {2673-4192},
  doi = {10.3389/frvir.2021.678875},
  urldate = {2023-01-13},
  abstract = {This study examines the plausibility of Auditory Augmented Reality (AAR) realized with position-dynamic binaural synthesis over headphones. An established method to evaluate the plausibility of AAR asks participants to decide whether they are listening to the virtual or real version of the sound object. To date, this method has only been used to evaluate AAR systems for seated listeners. The AAR realization examined in this study instead allows listeners to turn to arbitrary directions and walk towards, past, and away from a real loudspeaker that reproduced sound only virtually. The experiment was conducted in two parts. In the first part, the subjects were asked whether they are listening to the real or the virtual version, not knowing that it was always the virtual version. In the second part, the real versions of the scenes where the loudspeaker actually reproduced sound were added. Two different source positions, three different test stimuli, and two different sound levels were considered. Seventeen volunteers, including five experts, participated. In the first part, none of the participants noticed that the virtual reproduction was active throughout the different test scenes. The inexperienced listeners tended to accept the virtual reproduction as real, while experts distributed their answers approximately equally. In the second part, experts could identify the virtual version quite reliably. For inexperienced listeners, the individual results varied enormously. Since the presence of the headphones influences the perception of the real sound field, this shadowing effect had to be considered in the creation of the virtual sound source as well. This requirement still limits test methods considering the real version in its ecological validity. Although the results indicate that the availability of a hidden real reference leads to a more critical evaluation, it is crucial to be aware that the presence of the headphones slightly distorts the reference. This issue seems more vital to the plausibility estimates achieved with this evaluation method than the increased freedom in motion.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/D5VUCLWU/Neidhardt and Zerlik - 2021 - The Availability of a Hidden Real Reference Affect.pdf}
}


@conference{neidhardtFlexiblePythonTool2017,
		title = {Flexible Python Tool for Dynamic Binaural Synthesis Applications},
		author = {Neidhardt, Annika and Klein, Florian and Knoop, Niklas and Köllmer, Thomas},
		booktitle = {Audio Engineering Society Convention 142},
		month = {May},
		year = {2017},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=18721}
		}

@article{neidhardtPerceptualMatchingRoom2022a,
  title = {Perceptual {{Matching}} of {{Room Acoustics}} for {{Auditory Augmented Reality}} in {{Small Rooms}} - {{Literature Review}} and {{Theoretical Framework}}},
  author = {Neidhardt, A. and Schneiderwind, C. and Klein, F.},
  year = {2022},
  month = jan,
  journal = {Trends in Hearing},
  volume = {26},
  issn = {2331-2165, 2331-2165},
  doi = {10.1177/23312165221092919},
  urldate = {2023-02-21},
  abstract = {For the realization of auditory augmented reality (AAR), it is important that the room acoustical properties of the virtual elements are perceived in agreement with the acoustics of the actual environment. This perceptual matching of room acoustics is the subject reviewed in this paper. Realizations of AAR that fulfill the listeners' expectations were achieved based on pre-characterization of the room acoustics, for example, by measuring acoustic impulse responses or creating detailed room models for acoustic simulations. For future applications, the goal is to realize an online adaptation in (close to) real-time. Perfect physical matching is hard to achieve with these practical constraints. For this reason, an understanding of the essential psychoacoustic cues is of interest and will help to explore options for simplifications. This paper reviews a broad selection of previous studies and derives a theoretical framework to examine possibilities for psychoacoustical optimization of room acoustical matching.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/B3YF3CHX/Neidhardt et al. - 2022 - Perceptual Matching of Room Acoustics for Auditory.pdf}
}

@conference{neidhardtPlausibilityApproachingMotion2022,
  title = {Plausibility of an Approaching Motion towards a Virtual Sound Source {{II}}: {{In}} a Reverberant Seminar Room},
  shorttitle = {Plausibility of an Approaching Motion towards a Virtual Sound Source {{II}}},
  author = {Neidhardt, A. and Kamandi, S.},
  year = {2022},
  month = may,
  address={The Hague, Netherlands},
  note = {Paper 10608},
  booktitle = {Audio Engineering Society 152nd Convention},
  abstract = {This study investigates the plausibility of dynamic binaural audio scenarios wherein the listener interactively walks towards a virtual sound source. An originally measured BRIR set was manipulated and simplified systematically to challenge plausibility, explore its limits, and examine the relevance of selected acoustic properties.  After the first investigation in a quite dry listening laboratory, this second exploratory study repeats and extends the experiment in a considerably more reverberant room. The participants had to rate externalization, continuity, stability of the apparent sound source, impression of walking towards the sound source and the plausibility of the virtual acoustic scene. The results confirm the observations of the first study in the different acoustic environment. Both studies indicate much room for simplifications, but certain modifications seriously affect plausibility. Even inexperienced listeners notice if the progress of the auditory distance change does not match their own walking motion. In addition, the meaning of context and expectation for the perception of binaural audio is highlighted.}
}

@conference{neidhardtPlausibilityInteractiveApproaching2018,
		title = {Plausibility of an Interactive Approaching Motion towards a Virtual Sound Source Based on Simplified BRIR Sets},
		author = {Neidhardt, A. and Ignatious-Tommy, A. and Pereppadan, A. D.},
		booktitle = {Audio Engineering Society Convention 144},
		month = {May},
		year = {2018},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=19504}
		}
@inproceedings{nielsenAuditoryDistancePerception,
  title = {Auditory {{Distance Perception}} in {{Different Rooms}}},
  author = {Nielsen, Sores},
  file = {/home/MR/Documents/BLS/MA/Research/papers/6826.pdf}
}

@article{nilssonDevelopmentHearingNoise1994,
  title = {Development of the {{Hearing In Noise Test}} for the Measurement of Speech Reception Thresholds in Quiet and in Noise},
  author = {Nilsson, Michael and Soli, Sigfrid D. and Sullivan, Jean A.},
  year = {1994},
  month = feb,
  journal = {The Journal of the Acoustical Society of America},
  volume = {95},
  number = {2},
  pages = {1085--1099},
  issn = {0001-4966},
  doi = {10.1121/1.408469},
  urldate = {2023-03-06},
  langid = {english}
}

@book{organizacion2009iso,
  title = {{{ISO}} 3382-1: {{Acoustics}} - Measurement of Room Acoustic Parameters. {{Part}} 1 : {{Performance}} Rooms},
  author = {{Organizaci{\'o}n Internacional de Normalizaci{\'o}n}},
  year = {2009},
  publisher = {{ISO}},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/DDP4KXAI/ISO 3382-1.pdf}
}

@article{paulusPerceivedLevelLate2011,
  title = {Perceived {{Level}} of {{Late Reverberation}} in {{Speech}} and {{Music}}},
  month = {Jan.},
  author = {Paulus, Jouni and Uhle, Christian and Herre, J{\"u}rgen},
  year = {2011},
  journal = {130th Audio Engineering Society Convention},
  abstract = {This paper presents experimental investigations on the perceived level of running reverberation in various types of monophonic audio signals. The design and results of three listening tests are discussed. The tests focus on the influence of the input material, the direct-to-reverberation ratio (mixing level), and the reverberation time using artificially generated impulse responses for simulating the late reverberation. Furthermore, a comparison between mono and stereo reverberation is conducted.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/GG4SP93P/Paulus et al. - 2011 - Perceived Level of Late Reverberation in Speech an.pdf}
}

@article{pestanaUserPreferenceArtificial2017,
  title = {User {{Preference}} on {{Artificial Reverberation}} and {{Delay Time Parameters}}},
  author = {Pestana, Pedro Duarte and Reiss, Joshua and Barbosa, {\'A}lvaro},
  year = {2017},
  month = feb,
  journal = {Journal of the Audio Engineering Society},
  volume = {65},
  number = {1/2},
  pages = {100--107},
  issn = {15494950},
  doi = {10.17743/jaes.2016.0061},
  urldate = {2022-08-25},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/LJP6QL8T/Pestana et al. - 2017 - User Preference on Artificial Reverberation and De.pdf}
}

@article{plengeDifferencesLocalizationLateralization1974a,
  title = {On the Differences between Localization and Lateralization},
  author = {Plenge, G.},
  year = {1974},
  month = sep,
  journal = {The Journal of the Acoustical Society of America},
  volume = {56},
  number = {3},
  pages = {944--951},
  issn = {0001-4966},
  doi = {10.1121/1.1903353},
  note = {doi: 10.1121/1.1903353},
  urldate = {2023-01-28},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/GDAELMU7/Plenge - 1974 - On the differences between localization and latera.pdf}
}

@article{porschmannAuralizingListenerPosition2016,
  title = {Auralizing {{Listener Position Shifts}} of {{Measured Room Impulse Responses}}},
  author = {P{\"o}rschmann, Christoph and Stade, Philipp},
  year = {2016},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/25D88BWN/Pörschmann and Stade - 2016 - Auralizing Listener Position Shifts of Measured Ro.pdf}
}


@inproceedings{raakeQualityQualityExperience2014,
  title = {Quality and {{Quality}} of {{Experience}}},
  booktitle = {Quality of {{Experience}}},
  author = {Raake, Alexander and Egger, Sebastian},
  editor = {M{\"o}ller, Sebastian and Raake, Alexander},
  year = {2014},
  pages = {11--33},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-319-02681-7_2},
  urldate = {2023-03-08},
  abstract = {The chapter discusses the processes of human perception and experiencing, and of quality formation. In this context, definitions of relevant terms are re-visited and adapted to the presented, updated view, and different aspects of research into quality at large and into Quality of Experience are summarized. Using a conceptual model, the quality formation process is analyzed in view of different contexts and tasks, such as taking part in a quality test under controlled conditions, experiencing a video presentation or concert, or exploring a system or device when considering a purchase in a shop. We provide a short overview of different quality assessment methods, and outline related trends in QoE research.},
  isbn = {978-3-319-02680-0 978-3-319-02681-7},
  note = {isbn: 978-3-319-02680-0, 978-3-319-02681-7},
  langid = {english}
}

@misc{RaysWavesUnderstanding,
  title = {Rays\_or\_{{Waves}}\_{{Understanding}}\_the\_{{Strengths}}\_and\_{{Weak}}.Pdf - {{BLS Cloud}}},
  urldate = {2023-03-01},
  howpublished = {https://cloud.blssrv.de/apps/files/?dir=/interchange/im/Books\%20and\%20Literature/Room\%20Acoustics\&openfile=119692},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/89UAZJQ2/files.html}
}

@article{reichardtZusammenhangZwischenKlarheitsmass1975,
  title = {Zusammenhang Zwischen {{Klarheitsma\ss{} C}} Und Anderen Objektiven Raumakustischen {{Kriterien}}},
  author = {Reichardt, W. and Abdel Alim, O. and Schmidt, W.},
  year = {1975},
  journal = {Zeitschrift f\"ur elektrische Informations- und Energietechnik 5},
  number = {a},
  pages = {144--155},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/72E7CEZQ/index.html}
}

@conference{rubakArtificialReverberationBased1998,
  added-at = {2013-04-08T20:42:07.000+0200},
  author = {Rubak, P. and Johansen, L. G.},
  biburl = {https://www.bibsonomy.org/bibtex/2a6db9c9e19a26412e03f55b3bdc4974d/bovansnow},
  booktitle = {AES 104th Convention},
  howpublished = {Preprint 4725},
  interhash = {75524faf866bdc55ddeaaa92083ba9e5},
  intrahash = {a6db9c9e19a26412e03f55b3bdc4974d},
  keywords = {artificial impulse response reverberation},
  month = may,
  organization = {Amsterdam, Netherlands},
  timestamp = {2013-04-14T21:13:35.000+0200},
  title = {Artificial Reverberation Based on a Pseudo-Random Impulse Response},
  year = 1998
}

@book{ryanLinearAlgebraSignal2019,
  title = {Linear {{Algebra}}, {{Signal Processing}}, and {{Wavelets}} - {{A Unified Approach}}: {{Python Version}}},
  shorttitle = {Linear {{Algebra}}, {{Signal Processing}}, and {{Wavelets}} - {{A Unified Approach}}},
  author = {Ryan, {\O}yvind},
  year = {2019},
  series = {Springer {{Undergraduate Texts}} in {{Mathematics}} and {{Technology}}},
  publisher = {{Springer International Publishing}},
  address = {{Cham}},
  doi = {10.1007/978-3-030-02940-1},
  urldate = {2022-09-17},
  isbn = {978-3-030-02939-5 978-3-030-02940-1},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/IDEL5XXL/Ryan - 2019 - Linear Algebra, Signal Processing, and Wavelets - .pdf}
}

@article{saviojaCreatingInteractiveVirtual,
author = {Savioja, Lauri and Huopaniemi, J and Lokki, Tapio and R.~Väänänen},
year = {1999},
month = {Sept.},
pages = {675-705},
title = {Creating Interactive Virtual Acoustic Environments},
volume = {47},
journal = {Journal of the Audio Engineering Society}
}

@article{schaabDemonstratorAuralizationControl2017,
  title = {Demonstrator for the Auralization and Control of the Room Divergence Effect},
  author = {Schaab, M and Dobmeier, V and Werner, S and Klein, F},
  year = {2017},
  pages = {4},
  abstract = {The goal of binaural headphone reproduction is to synthesize a virtual room or to resynthesize the acoustics of a real room. Former research has shown, that the acoustical divergence between the room presented over headphones and the actual listening room can violate the expectations of the listener. In this case, the perceived quality of the synthesized room is degraded despite of a technical correct synthesis of the ear signals. This effect is called room divergence effect and is measured in a reduction of externalization of sound events. This publication describes a demonstrator which auralizes this effect. For this purpose a 5 channel loudspeaker setup is measured with a KEMAR artificial head in two rooms. Additionally three algorithms are implemented to calculate virtual rooms in between the measured rooms. By listening to the unmodified rooms measurements and their modifications differences in externalization are distinguishable. The influence of each algorithm on externalization in a divergent listening scenario is evaluated in a listening test with 14 participants.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/9IGJQ6JE/Schaab et al. - 2017 - Demonstrator for the auralization and control of t.pdf}
}


@PHDTHESIS{schroderPhysicallyBasedRealTime,
      author       = {Schröder, Dirk},
      othercontributors = {Vorländer, Michael},
      title        = {{P}hysically based real-time auralization of interactive
                      virtual environments},
      volume       = {11},
      address      = {Berlin},
      publisher    = {Logos-Verl.},
      reportid     = {RWTH-CONV-113120},
      series       = {Aachener Beiträge zur technischen Akustik},
      pages        = {XVIII, 206 S. : Ill., graph. Darst.},
      year         = {2011},
      note         = {Zsfassung in dt. und engl. Sprache. - Druckausgabe: 2011. -
                      Onlineausgabe: 2012; Zugl.: Aachen, Techn. Hochsch., Diss.,
                      2011},
      abstract     = {Over the last decades, Virtual Reality (VR) technology has
                      emerged to be a powerful tool for a wide variety of
                      applications covering conventional use, e.g., in science,
                      design, medicine and engineering, as well as in more
                      visionary applications such as the creation of virtual
                      spaces that aim to act real. However, the high capabilities
                      of today's VR-systems are mostly limited to first-class
                      visual rendering. In order to boost the range of
                      applications, state-of-the-art systems aim to reproduce
                      virtual environments as realistically as possible for the
                      purpose of maximizing the user's feeling of immersion,
                      presence and acceptance. Such immersive systems deliver
                      multiple sensory stimuli and provide an opportunity to act
                      interactively, as reality is neither mono-modal nor static.
                      Analogous to visualization, the auralization of virtual
                      environments describes the simulation of sound propagation
                      inside enclosures where methods of Geometrical Acoustics are
                      mostly applied for a high-quality synthesis of aural stimuli
                      that go along with a certain realistic behavior. Here, best
                      results are achieved by combining deterministic methods for
                      the computation of early specular sound reflections with
                      stochastic approaches for the computation of the reverberant
                      sound field. By adapting acceleration algorithms from
                      Computer Graphics, current implementations can manage the
                      computational load of moving sound sources around a moving
                      receiver in real-time - even for complex but static
                      architectural scenarios. In the course of this thesis, the
                      design and implementation of the real-time room acoustics
                      simulation software RAVEN will be described, which is a
                      vital part of the implemented 3D sound-rendering system of
                      RWTH Aachen University's immersive VR-system. RAVEN relies
                      on present-day knowledge of room acoustical simulation
                      techniques and enables a physically accurate auralization of
                      sound propagation in complex environments including
                      important wave effects such as sound scattering, airborne
                      sound insulation between rooms and sound diffraction.
                      Despite this realistic sound field rendering, not only
                      spatially distributed and freely movable sound sources and
                      receivers are supported at runtime but also modifications
                      and manipulations of the environment itself. All major
                      features are evaluated by investigating both the overall
                      accuracy of the room acoustics simulation and the
                      performance of implemented algorithms, and possibilities for
                      further simulation optimizations are identified by assessing
                      empirical studies of subjects operating in immersive
                      environments.},
      keywords     = {Virtuelle Realität (SWD) / Raumakustik (SWD) /
                      Echtzeitsimulation (SWD) / Immersion <Virtuelle Realität>
                      (SWD) / Binaurales Hören (SWD)},
      cin          = {613510},
      ddc          = {620},
      cid          = {$I:(DE-82)613510_20140620$},
      shelfmark    = {43.55.Ka * 43.66.Pn * 43.20.Dk * 43.20.El * 43.20.Fn},
      typ          = {PUB:(DE-HGF)11},
      urn          = {urn:nbn:de:hbz:82-opus-38759},
      url          = {https://publications.rwth-aachen.de/record/50580},
}


@article{schroederNewMethodMeasuring1965,
  title = {New {{Method}} of {{Measuring Reverberation Time}}},
  author = {Schroeder, M. R.},
  year = {1965},
  month = mar,
  journal = {The Journal of the Acoustical Society of America},
  volume = {37},
  number = {3},
  pages = {409--412},
  publisher = {{Acoustical Society of America}},
  issn = {0001-4966},
  doi = {10.1121/1.1909343},
  urldate = {2023-03-24}
}
@unpublished{annikasixpoint,
author = {Neidhardt, A},
title = {Effect of impaired early reflection patterns on plausibility and similarity of position-dynamic binaural AR audio},
year={2023},
note={unpublished}
}
@article{schroederStatisticalParametersFrequency1987,
  title = {Statistical {{Parameters}} of the {{Frequency Response Curves}} of {{Large Rooms}}},
  author = {Schroeder, Manfred R.},
  year = {1987},
  month = may,
  journal = {Journal of the Audio Engineering Society},
  volume = {35},
  number = {5},
  pages = {299--306},
  publisher = {{Audio Engineering Society}},
  urldate = {2023-03-01},
  abstract = {The following statistical quantities of the frequency response curve of 'large rooms' are calculated: the rms response fluctuation, the average height of the maximum, the mean spacing of the zeros (i.e., the intersections of the response curve with the mean level), the mean spacing of the maxima, the mean rate of phase rotation per hertz, and finally the so-called frequence irregularity.: These quantities are exclusively dependent on the reverberation time of the room if certain conditions are...},
  langid = {english}
}

@article{shinn-cunninghamLearningReverberationConsiderations2000,
  title = {Learning {{Reverberation}}: {{Considerations}} for {{Spatial Auditory Displays}}},
  shorttitle = {Learning {{Reverberation}}},
  author = {{Shinn-Cunningham}, Barbara},
  year = {2000},
  month = jul,
  journal = {International Conference on Auditory Display},
  abstract = {Reverberation has both beneficial and detrimental effects on auditory localization. This paper reviews evidence that listeners adapt to the reverberation in a room. Results show that reverberation degrades perception of source direction, but with experience in a given room, performance improves. Reverberation enhances distance perception but distance accuracy still improves with experience. (The importance of reverberation for distance perception can be heard in the accompanying demonstration.) These results are considered along with results from previous studies investigating how past experience affects spatial perception. Implications for learning mechanisms and for the design of auditory displays are discussed.},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/9NGKKPYV/Shinn-Cunningham - 2000 - Learning Reverberation Considerations for Spatial.pdf}
}

@inproceedings{siltanenRaysWavesUnderstanding2010,
  title = {Rays or {{Waves}}? {{Understanding}} the {{Strengths}} and {{Weaknesses}} of {{Computational Room Acoustics Modeling Techniques}}},
  shorttitle = {Rays or {{Waves}}?},
  author = {Siltanen, Samuel and Lokki, Tapio and Savioja, Lauri},
  year = {2010},
  month = jan,
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/CYH8VYKH/Siltanen 등 - 2010 - Rays or Waves Understanding the Strengths and Wea.pdf}
}

@Article{Slutsky2001,
  author    = {Slutsky, Daniel A and Recanzone, Gregg H},
  title     = {Temporal and spatial dependency of the ventriloquism effect},
  journal   = {NeuroReport},
  year      = {2001},
  volume    = {12},
  number    = {1},
  pages     = {7--10},
}

@Article{Medonca2016,
  author    = {Medon{\c{c}}a, Catarina and Mandelli, Pietro and Pulkki, Ville},
  title     = {Modeling the perception of audiovisual distance: Bayesian causal inference and other models},
  journal   = {PloS ONE},
  year      = {2016},
  volume    = {11},
  number    = {12},
  pages     = {e0165391},
  doi       = {10.1371/journal.pone.0165391},
}

@article{Authenticity,
    author = {Brinkmann, F. and Lindau, A. and Weinzierl, S.},
    title = "{On the authenticity of individual dynamic binaural synthesis}",
    journal = {The Journal of the Acoustical Society of America},
    volume = {142},
    number = {4},
    pages = {1784-1795},
    year = {2017},
    month = {10},
    abstract = "{A simulation that is perceptually indistinguishable from the corresponding real sound field could be termed authentic. Using binaural technology, such a simulation would theoretically be achieved by reconstructing the sound pressure at a listener's ears. However, inevitable errors in the measurement, rendering, and reproduction introduce audible degradations, as it has been demonstrated in previous studies for anechoic environments and static binaural simulations (fixed head orientation). The current study investigated the authenticity of individual dynamic binaural simulations for three different acoustic environments (anechoic, dry, wet) using a highly sensitive listening test design. The results show that about half of the participants failed to reliably detect any differences for a speech stimulus, whereas all participants were able to do so for pulsed pink noise. Higher detection rates were observed in the anechoic condition, compared to the reverberant spaces, while the source position had no significant effect. It is concluded that the authenticity mainly depends on how comprehensive the spectral cues are provided by the audio content, and the amount of reverberation, whereas the source position plays a minor role. This is confirmed by a broad qualitative evaluation, suggesting that remaining differences mainly affect the tone color rather than the spatial, temporal or dynamical qualities.}",
    issn = {0001-4966},
    doi = {10.1121/1.5005606},
    url = {https://doi.org/10.1121/1.5005606},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/142/4/1784/15324824/1784\_1\_online.pdf},
}


@inproceedings{silzleGenerationQualityTaxonomies,
title = {Generation of {{Quality Taxonomies}} for {{Auditory Virtual Environments}} by {{Means}} of a {{Systematic Expert Survey}}},
author = {Silzle, Andreas},
year = "2007",
month = mar,
language = "English",
booktitle = "Fortschritte der Akustik - DAGA 2007",
publisher = "German Acoustical Society (DEGA)",
}

@conference{sporsTheoryWaveField2008,
		title = {The Theory of Wave Field Synthesis Revisited},
		author = {Ahrens, Jens and Rabenstein, Rudolph and Spors, Sascha},
		booktitle = {Audio Engineering Society Convention 124},
		month = {May},
		year = {2008},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=14488}
		}


@article{stadePerzeptiveUntersuchungZur2015,
  title = {{Perzeptive Untersuchung zur mixing time und deren  Einfluss auf die Auralisation}},
  author = {Stade, Philipp},
  year = {2015},
  langid = {ngerman},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/FV8DYN9G/Stade - 2015 - Perzeptive Untersuchung zur mixing time und deren .pdf}
}

@article{stewartStatisticalMeasuresEarly2007,
  title = {Statistical {{Measures}} of {{Early Reflections}} of {{Room Impulse Responses}}},
  author = {Stewart, Rebecca and Sandler, Mark},
  year = {2007},
  month = {Sept.},
  journal  ={Proc. of the 10th Int. Conference on Digital Audio Effects (DAFx-07)},
  abstract = {An impulse response of an enclosed reverberant space is composed of three basic components: the direct sound, early reflections and late reverberation. While the direct sound is a single event that can be easily identified, the division between the early reflections and late reverberation is less obvious as there is a gradual transition between the two.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/RRUFML2Y/Stewart and Sandler - 2007 - Statistical Measures of Early Reflections of Room .pdf}
}

@article{tervoSpatialDecompositionMethod2013,
  title = {Spatial {{Decomposition Method}} for {{Room Impulse Responses}}},
  author = {Tervo, Sakari and Tynen, Jukka Pa and Kuusinen, Antti and Lokki, Tapio},
  year = {2013},
  journal = {J. Audio Eng. Soc.},
  volume = {61},
  number = {1},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/C8MW5574/Tervo et al. - 2013 - Spatial Decomposition Method for Room Impulse Resp.pdf}
}

@article{torcoliObjectiveMeasuresPerceptual2021,
  title = {Objective {{Measures}} of {{Perceptual Audio Quality Reviewed}}: {{An Evaluation}} of {{Their Application Domain Dependence}}},
  shorttitle = {Objective {{Measures}} of {{Perceptual Audio Quality Reviewed}}},
  author = {Torcoli, Matteo and Kastner, Thorsten and Herre, Jurgen},
  year = {2021},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {29},
  pages = {1530--1541},
  issn = {2329-9290, 2329-9304},
  doi = {10.1109/TASLP.2021.3069302},
  urldate = {2023-01-18},
  abstract = {Over the past few decades, computational methods have been developed to estimate perceptual audio quality. These methods, also referred to as objective quality measures, are usually developed and intended for a specific application domain. Because of their convenience, they are often used outside their original intended domain, even if it is unclear whether they provide reliable quality estimates in this case. This work studies the correlation of well-known state-of-the-art objective measures with human perceptual scores in two different domains: audio coding and source separation. The following objective measures are considered: fwSNRseg, dLLR, PESQ, PEAQ, POLQA, PEMO-Q, ViSQOLAudio, (SI-)BSSEval, PEASS, LKR-PI, 2f-model, and HAAQI. Additionally, a novel measure (SI-SA2f) is presented, based on the 2f-model and a BSSEval-based signal decomposition. We use perceptual scores from 7 listening tests about audio coding and 7 listening tests about source separation as ground-truth data for the correlation analysis. The results show that one method (2f-model) performs significantly better than the others on both domains and indicate that the dataset for training the method and a robust underlying auditory model are crucial factors towards a universal, domainindependent objective measure.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/XVCHXGNB/Torcoli et al. - 2021 - Objective Measures of Perceptual Audio Quality Rev.pdf}
}

@article{usherImprovedMethodDetermine2010,
  title = {An Improved Method to Determine the Onset Timings of Reflections in an Acoustic Impulse Response},
  author = {Usher, John},
  year = {2010},
  journal = {J. Acoust. Soc. Am.},
  pages = {7},
  abstract = {Determining the absolute onset time of reflections in an acoustic impulse response (IR) has applications for both subjective and physical acoustics problems. Although computationally simple, a first-order energetic analysis of the IR can lead to false-positive identification of reflections. This letter reports on a method to determine reflection onset timings using a modified running local kurtosis analysis to identify regions in the IR where the distribution is non-normal. IRs from both real and virtual rooms are used to validate the method and to find optimum analysis window sizes.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/EFGH28SM/Usher - 2010 - An improved method to determine the onset timings .pdf}
}

@article{valimakiFiftyYearsArtificial2012,
  title = {Fifty {{Years}} of {{Artificial Reverberation}}},
  author = {Valimaki, Vesa and Parker, Julian D. and Savioja, Lauri and Smith, Julius O. and Abel, Jonathan S.},
  year = {2012},
  month = jul,
  journal = {IEEE Transactions on Audio, Speech, and Language Processing},
  volume = {20},
  number = {5},
  pages = {1421--1448},
  issn = {1558-7916, 1558-7924},
  doi = {10.1109/TASL.2012.2189567},
  urldate = {2022-08-25},
  abstract = {The first artificial reverberation algorithms were proposed in the early 1960s, and new, improved algorithms are published regularly. These algorithms have been widely used in music production since the 1970s, and now find applications in new fields, such as game audio. This overview article provides a unified review of the various approaches to digital artificial reverberation. The three main categories have been delay networks, convolutionbased algorithms, and physical room models. Delay-network and convolution techniques have been competing in popularity in the music technology field, and are often employed to produce a desired perceptual or artistic effect. In applications including virtual reality, predictive acoustic modeling, and computer-aided design of acoustic spaces, accuracy is desired, and physical models have been mainly used, although, due to their computational complexity, they are currently mainly used for simplified geometries or to generate reverberation impulse responses for use with a convolution method. With the increase of computing power, all these approaches will be available in real time. A recent trend in audio technology is the emulation of analog artificial reverberation units, such as spring reverberators, using signal processing algorithms. As a case study we present an improved parametric model for a spring reverberation unit.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/BWB7YNJH/Valimaki et al. - 2012 - Fifty Years of Artificial Reverberation.pdf}
}

@article{valimakiLateReverberationSynthesisUsing2021,
  title = {Late-{{Reverberation Synthesis Using Interleaved Velvet-Noise Sequences}}},
  author = {Valimaki, Vesa and Prawda, Karolina},
  year = {2021},
  journal = {IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume = {29},
  pages = {1149--1160},
  issn = {2329-9290, 2329-9304},
  doi = {10.1109/TASLP.2021.3060165},
  urldate = {2022-08-25},
  abstract = {This paper proposes a novel algorithm for simulating the late part of room reverberation. A well-known fact is that a room impulse response sounds similar to exponentially decaying filtered noise some time after the beginning. The algorithm proposed here employs several velvet-noise sequences in parallel and combines them so that their non-zero samples never occur at the same time. Each velvet-noise sequence is driven by the same input signal but is filtered with its own feedback filter which has the same delay-line length as the velvet-noise sequence. The resulting response is sparse and consists of filtered noise that decays approximately exponentially with a given frequency-dependent reverberation time profile. We show via a formal listening test that four interleaved branches are sufficient to produce a smooth high-quality response. The outputs of the branches connected in different combinations produce decorrelated output signals for multichannel reproduction. The proposed method is compared with a state-of-the-art delay-based reverberation method and its advantages are pointed out. The computational load of the method is 60\% smaller than that of a comparable existing method, the feedback delay network. The proposed method is well suited to the synthesis of diffuse late reverberation in audio and music production.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/N6ABGEUW/Valimaki and Prawda - 2021 - Late-Reverberation Synthesis Using Interleaved Vel.pdf}
}

@book{vorlanderAuralization2008,
  title = {Auralization: {{Fundamentals}} of Acoustics, Modelling, Simulation, Algorithms and Acoustic Virtual Reality},
  author = {Vorl{\"a}nder, M.},
  year = {2007},
  series = {{{RWTHedition}}},
  publisher = {{Springer Berlin Heidelberg}},
  isbn = {978-3-540-48830-9},
  note = {isbn: 978-3-540-48830-9},
  lccn = {2007932291}
}

@article{vorlanderDefinitionMeasurementRandomincidence2000,
  title = {Definition and Measurement of Random-Incidence Scattering Coefficients},
  author = {Vorl{\"a}nder, Michael and Mommertz, Eckard},
  year = {2000},
  month = jun,
  journal = {Applied Acoustics},
  volume = {60},
  number = {2},
  pages = {187--199},
  issn = {0003-682X},
  doi = {10.1016/S0003-682X(99)00056-0},
  note = {doi: 10.1016/S0003-682X(99)00056-0},
  urldate = {2023-03-24},
  abstract = {This paper describes the definition and two methods for measuring scattering coefficients of rough surfaces. In both cases, impulse responses are determined for various orientations of a sample surface. After phase-locked superposition of a sufficient number of impulse responses, the coherent reflected sound energy is obtained. It is identical with the zero-order lobe of the reflection pattern~\textemdash{} the specularly reflected part. Considering the totally reflected sound energy, the scattering coefficients can be calculated. The results of the reverberation chamber measurements are scattering coefficients for random sound incidence. Both methods are discussed and experimental results, obtained by scale model measurements, are shown.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/WKZYAEXE/S0003682X99000560.html}
}

@inproceedings{vorlanderWhatWeKnow2011,
  title = {What Do We Know in Room Acoustics?},
  author = {Vorl{\"a}nder, Michael},
  adress = {Aalborg, Denmark},
  organization = {Danish Acoustical Society (DAS) on behalf of European Acoustics Association (EAA)},
  booktitle = {Proceedings of Forum Acusticum},
month = {June},
  year = {2011},
  urldate = {2023-03-28},
  abstract = {Room acoustics has a scientific interdisciplinary concept which will be further developed in future. During the last century, several dimensions of the overall listening impression in concert halls were identified which show a good correlation with corresponding objective measurement data. It can be summarized that the three most important factors (loudness, reverberance and spatial impression) explain most of the statistical variance when comparing the acoustic conditions in auditoria. But some questions remain, particularly for stage acoustics, for dependencies within the quantities and for the overall impression. In applied room acoustics, progress can be seen concerning modeling and simulation on the one hand, and impulse response measurements on the other. Apart from the perceptual factors of room acoustics, another crucial point is the listener's sensitivity to changes in a sound field in regard to those subjective aspects. In the end, the uncertainties of simulation and measurement results must be compared with the just noticeable differences, jnd, of hearing in rooms. Thus, further cooperation of room acoustics with psychoacoustics and audio engineering is expected to stimulate more ideas and innovation in research and concert hall design.},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/8HSYKTIQ/Vorländer - 2011 - What do we know in room acoustics .pdf}
}

@book{wefersPartitionedConvolutionAlgorithms2015,
  title = {Partitioned Convolution Algorithms for Real-Time Auralization},
  author = {Wefers, Frank},
  year = {2015},
  series = {Aachener {{Beitr\"age}} Zur Technischen {{Akustik}}},
  number = {Band 20},
  publisher = {{Logos Verlag Berlin GmbH}},
  address = {{Berlin}},
  isbn = {978-3-8325-3943-6},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/TF3NC9LY/Wefers - 2015 - Partitioned convolution algorithms for real-time a.pdf}
}

@article{wehrmannDeviceGeneratingSurface1965,
  title = {Device for {{Generating Surface Waves}} with {{Adjustable Speed}}},
  author = {Wehrmann, O. H. and Lundberg, J. L.},
  year = {1965},
  month = jun,
  journal = {The Journal of the Acoustical Society of America},
  volume = {37},
  number = {6},
  pages = {1149--1150},
  issn = {0001-4966},
  doi = {10.1121/1.1909554},
  urldate = {2023-03-02},
  langid = {english}
}

@conference{wernerAdjustmentDirecttoReverberantEnergyRatioReach2016,
		title = {Adjustment of the direct-to-Reverberant-Energy-Ratio to Reach Externalization within a Binaural Synthesis System},
		author = {Werner, Stephan and Klein, Florian and Sporer, Thomas},
		booktitle = {Audio Engineering Society Conference: 2016 AES International Conference on Audio for Virtual and Augmented Reality},
		month = {Sep},
		year = {2016},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=18513}
		}

@article{wernerCreationAuditoryAugmented2021,
  title = {Creation of {{Auditory Augmented Reality Using}} a {{Position-Dynamic Binaural Synthesis System}}\textemdash{{Technical Components}}, {{Psychoacoustic Needs}}, and {{Perceptual Evaluation}}},
  author = {Werner, Stephan and Klein, Florian and Neidhardt, Annika and Sloma, Ulrike and Schneiderwind, Christian and Brandenburg, Karlheinz},
  year = {2021},
  month = jan,
  journal = {Applied Sciences},
  volume = {11},
  number = {3},
  pages = {1150},
  issn = {2076-3417},
  doi = {10.3390/app11031150},
  note = {doi: 10.3390/app11031150},
  urldate = {2022-08-10},
  abstract = {For a spatial audio reproduction in the context of augmented reality, a position-dynamic binaural synthesis system can be used to synthesize the ear signals for a moving listener. The goal is the fusion of the auditory perception of the virtual audio objects with the real listening environment. Such a system has several components, each of which help to enable a plausible auditory simulation. For each possible position of the listener in the room, a set of binaural room impulse responses (BRIRs) congruent with the expected auditory environment is required to avoid room divergence effects. Adequate and efficient approaches are methods to synthesize new BRIRs using very few measurements of the listening room. The required spatial resolution of the BRIR positions can be estimated by spatial auditory perception thresholds. Retrieving and processing the tracking data of the listener's head-pose and position as well as convolving BRIRs with an audio signal needs to be done in real-time. This contribution presents work done by the authors including several technical components of such a system in detail. It shows how the single components are affected by psychoacoustics. Furthermore, the paper also discusses the perceptive effect by means of listening tests demonstrating the appropriateness of the approaches.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/3ZMVEAVR/Werner et al. - 2021 - Creation of Auditory Augmented Reality Using a Pos.pdf}
}

@article{wernerInfluenceContextDependent2014,
  title = {Influence of Context Dependent Quality Parameters on the Perception of Externalization and Direction of an Auditory Event},
  author = {Werner, Stephan and Klein, Florian},
  year = {2014},
  journal = {Proceedings of the AES International Conference},
  publisher = {{Unpublished}},
  doi = {10.13140/RG.2.1.1991.4328},
  note = {doi: 10.13140/RG.2.1.1991.4328},
  urldate = {2022-08-24},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/HI6VRTDT/Werner and Klein - 2014 - Influence of context dependent quality parameters .pdf}
}

@inproceedings{wernerSummaryAcousticRoom2016,
  title = {A Summary on Acoustic Room Divergence and Its Effect on Externalization of Auditory Events},
  booktitle = {2016 {{Eighth International Conference}} on {{Quality}} of {{Multimedia Experience}} ({{QoMEX}})},
  author = {Werner, S. and Klein, F. and Mayenfels, T. and Brandenburg, K.},
  year = {2016},
  month = jun,
  pages = {1--6},
  publisher = {{IEEE}},
  address = {{Lisbon, Portugal}},
  doi = {10.1109/QoMEX.2016.7498973},
  note = {doi: 10.1109/QoMEX.2016.7498973},
  urldate = {2022-08-10},
  abstract = {This contribution presents a summary of results from perceptual auditory experiments on context dependent quality parameters for virtual acoustic environments. The investigated quality features are influenced by divergence between synthesized scene and listening room and adaptation on congruence or divergence between the rooms. Two experiments are presented. The results from the first experiment show the room divergence effect on spatial auditory perception. A divergence between the listening room and binaurally synthesized room leads to a decrease of perceived externalization while congruence yields an increase. A more comprehensive statistical analysis regarding significance, effect size and visual influences is added to complement the original publication of this data. The second experiment shows this effect as the result of expectations of the listeners and can be shifted by adaptation and training. In the experiments we show, that training to congruent or divergent room combinations can increase or decrease the room divergence effect.},
  isbn = {978-1-5090-0354-9},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/EIW3SIQZ/Werner et al. - 2016 - A summary on acoustic room divergence and its effe.pdf}
}

@conference{NEIDHARDT:POAIAMSR:2020,
  author = {Neidhardt, Annika and Kamandi, Samaneh},
  title  = {Plausibility of an interactive approaching motion towards a virtual sound source in a seminar room},
  booktitle = {Audio Engineering Society Convention 152},
  month = {May},
  year = {2022},
}

@conference{wierstorf2011a,
		title = {A Free Database of Head Related Impulse Response Measurements in the Horizontal Plane with Multiple Distances},
		author = {Wierstorf, Hagen and Geier, Matthias and Spors, Sascha},
		booktitle = {Audio Engineering Society Convention 130},
		month = {May},
		year = {2011},
		url = {http://www.aes.org/e-lib/browse.cfm?elib=16564}
		}

@book{xieHeadrelatedTransferFunction2013,
  title = {Head-Related Transfer Function and Virtual Auditory Display},
  author = {Xie, Bosun},
  year = {2013},
  edition = {Second edition},
  publisher = {{J. Ross Publishing}},
  address = {{Plantation, FL}},
  isbn = {978-1-60427-070-9},
  langid = {english},
  lccn = {TK7881.83 .X54 2013},
  keywords = {Auditory perception,Sound in virtual reality,Surround-sound systems,Virtual reality},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/V8D8NK4A/Xie - 2013 - Head-related transfer function and virtual auditor.pdf}
}

@book{yostAuditoryPerceptionSound2008,
  title = {Auditory Perception of Sound Sources},
  editor = {Yost, William A. and Popper, Arthur N. and Fay, Richard R.},
  year = {2008},
  series = {Springer Handbook of Auditory Research},
  number = {29},
  publisher = {{Springer}},
  address = {{New York}},
  isbn = {978-0-387-71304-5 978-0-387-71305-2},
  langid = {english},
  lccn = {BF251 .A93 2008},
  keywords = {Auditory perception,Auditory Perception},
  annotation = {OCLC: ocn190966656},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/7QLZ5KP3/Yost et al. - 2008 - Auditory perception of sound sources.pdf}
}

@article{zahorikAuditoryDisplaySound2002,
  title = {Auditory Display of Sound Source Distance},
  author = {Zahorik, Pavel},
  year = {2002},
  month = jul,
  journal = {Proceedings of the 2002 International Conference on Auditory Display, Kyoto, Japan},
  abstract = {Although the majority of research on spatial sound reproduction has concentrated on the directional components of source location, it is clear that full 3-dimensional rendering also requires an understanding of how to reproduce sound source distance. This article reviews and describes recent psychophysical research on distance perception of sound sources, with emphasis on how various acoustical and nonacoustical factors contribute to perceived distance. Results from this research have important implications for distance simulation and reproduction in spatial auditory displays.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/DBC7UD5E/Zahorik - 2002 - AUDITORY DISPLAY OF SOUND SOURCE DISTANCE.pdf}
}

@article{zahorikAuditoryDistancePerception2005,
  title = {Auditory {{Distance Perception}} in {{Humans}}: {{A Summary}} of {{Past}} and {{Present Research}}},
  author = {Zahorik, Pavel},
  year = {2005},
  journal = {Acta Acustica united with Acustica},
  volume = {91},
  pages = {409--420},
  abstract = {Although auditory distance perception is a critical component of spatial hearing, it has received substantially less scientific attention than the directional aspects of auditory localization. Here we summarize current knowledge on auditory distance perception, with special emphasis on recent research results. The summary will be structured around three central questions. 1. How accurately can humans estimate the distances of stationary sound sources? We show that this psychophysical relationship is well approximated by a compressive power function, which suggests that listeners systematically underestimate distances to faraway sound sources. 2. What determines perceived sound source distance? We examine the various acoustical and non-acoustical factors thought to contribute to source distance percepts, and summarize the psychophysical literature relevant to each factor. 3. What are the neural correlates to perceived sound source distance? Recent evidence points to the role of areas within right temporal cortex in auditory distance perception, as well as in other spatial tasks in different sensory modalities.},
  langid = {english},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/RV55F8DL/Zahorik - 2005 - Auditory Distance Perception in Humans A Summary .pdf}
}

@inproceedings{zahorikPerceptualAdaptationRoom2011,
  title = {Perceptual {{Adaptation}} to {{Room Acoustics}} and {{Effects}} on {{Speech Intelligibility}} in {{Hearing-Impaired Populations}}},
  author = {Zahorik, Pavel and Brandewie, Eugene},
  year = {2011},
  month = jun,
  booktitle = {Proceedings of Forum
Acusticum 2011 Jun 27:2167-2172.},
  issn = {2221-3767},
  urldate = {2023-03-28},
  abstract = {Recent evidence suggests that brief listening exposure to a reverberant room environment can improve closed-set speech intelligibility in that same environment. For normal-hearing populations, this room adaptation effect can result in improvements in intelligibility of as much as 20\%, but depends strongly on the reverberation time of the room, and appears to require binaural input. Because poor speech intelligibility in reverberation is a common complaint for hearing-impaired listeners, it is important to determine how room adaptation might impact speech intelligibility for hearing-impaired populations. Here, room adaptation was quantified for a sample of listeners with sensorineural hearing loss that varied in severity and configuration. Speech reception thresholds (SRTs) were measured both with and without prior listening exposure to the room environment. Headphone-based auralization techniques were used to simulate the acoustics of various listening rooms, ranging from anechoic to highly reverberant space (broadband T60 = 3 s). Although SRTs both with and without prior room exposure were found to be generally elevated relative to normal-hearing listeners, the room adaptation effect, as defined by the relative decrease in SRT with room exposure, was comparable on average to that observed for normal-hearing listeners. This result is consistent with the view that room adaptation effects result from central auditory processing mechanisms.},
  pmcid = {PMC3582192},
  pmid = {23455358},
  file = {/home/MR/snap/zotero-snap/common/Zotero/storage/MV9W26ZA/Zahorik und Brandewie - 2011 - Perceptual Adaptation to Room Acoustics and Effect.pdf}
}

@Inbook{zahorikSpatialHearingRooms2021,
author="Zahorik, Pavel",
editor="Litovsky, Ruth Y.
and Goupell, Matthew J.
and Fay, Richard R.
and Popper, Arthur N.",
title="Spatial Hearing in Rooms and Effects of Reverberation",
bookTitle="Binaural Hearing: With 93 Illustrations",
year="2021",
publisher="Springer International Publishing",
address="Cham",
pages="243--280",
note = "isbn: 978-3-030-57100-9",
abstract="This chapter provides a multidisciplinary overview of the impacts of room acoustics and reflected sound on various human listening abilities. General concepts in the physical quantification of room acoustic effects are described, including impulse-response measures and a variety of other measures designed to predict aspects of sound perception and listening performance. Key areas and concepts in psychoacoustical research related to room listening environments are then summarized, including: basic sensitivity to room acoustic effects, sound localization in direction and distance, and speech intelligibility. The effects on subjective sound quality are also summarized, primarily related to the application of concert hall acoustics. Where known, neural bases and the impacts of hearing loss are discussed.",
isbn="978-3-030-57100-9",
doi="10.1007/978-3-030-57100-9_9",
url="https://doi.org/10.1007/978-3-030-57100-9_9"
}

@incollection{zotterAmbisonicsPractical3D2019,
  title = {Ambisonics: A Practical {{3D}} Audio Theory for Recording, Studio Production, Sound Reinforcement, and Virtual Reality},
  booktitle = {Ambisonics},
  author = {Zotter, Franz and Frank, Matthias},
  year = {2019},
  series = {Springer Topics in Signal Processing},
  number = {volume 19},
  publisher = {{SpringerOpen}},
  address = {{Cham}},
  isbn = {978-3-030-17206-0},
  note = {isbn: 978-3-030-17206-0},
  langid = {english}
}

@book{zwickerPsychoacousticsFactsModels1999,
  title = {Psychoacoustics: Facts and Models},
  shorttitle = {Psychoacoustics},
  author = {Zwicker, Eberhard and Fastl, H.},
  year = {1999},
  series = {Springer Series in Information Sciences},
  edition = {2nd updated ed},
  number = {22},
  publisher = {{Springer}},
  address = {{Berlin ; New York}},
  isbn = {978-3-540-65063-8 978-3-540-52600-1},
  isbn = {isbn: 978-3-540-65063-8, 978-3-540-52600-1},
  lccn = {QP461 .Z92 1999},
  keywords = {Psychoacoustics}
}


%examples of reference to a book
@book{Mitra:Kaiser:1993:DSP:handbook,
	 Editor = {S.~K. Mitra and J.~F. Kaiser},
	 Title = {Handbook for Digital Signal Processing},
	 Publisher = {J. Wiley {\&} Sons},
         Address = {New York, NY, USA},
	 Year = {1993}
 }
 
 @book{Haykin:1991:adaptive:filter,
	Author = {Simon Haykin},
	Title = {Adaptive Filter Theory},
	Publisher = {Prentice Hall},
	Address = {Englewood Cliffs, NJ, USA},
	Edition = {Second},
	Year = 1991}

%example of reference to a book chapter
@inbook{Serra:1996:sms,
	Author = {X. Serra},
	Chapter = {Musical Sound Modeling with Sinusoids plus Noise},
	Publisher = {G. D. Poli, A. Picialli, S. T. Pope, and C. Roads Eds. Swets \& Zeitlinger},
        Address = {Lisse, Switzerland},
	Title = {Musical Signal Processing},
	Pages = {91--122}, 
	Year = {1996}}

%example of reference to a journal paper
@article{Moorer:2000:AES:audio:millenium,
	Author = {James A. Moorer},
	Title = {Audio in the new millennium},
	Journal = {J. Audio Eng. Soc.},
	Volume = 48,
	Number = 5,
	Year = 2000,
	Month = may,
	Pages = {490--498}}


%example of reference to a proceedings paper
@InProceedings{Nackaerts:2001:ICMC,
  Author = 	 {A. Nackaerts and B. {De Moor} and R. Lauwereins},
  Title = 	 {Parameter estimation for dual-polarization plucked string models},
  Booktitle = 	 {Proc. Intl. Computer Music Conf.},
  Pages = 	 {203--206},
  Year = 	 {2001},
  Address = 	 {Havana, Cuba},
  Month = 	 {Sept. 17-23,}}

%example of reference to a proceeding paper
@inproceedings{Arfib:1998:DAFx,
	Author = {D. Arfib},
	Booktitle = {Proc. Digital Audio Effects (DAFx-98)},
	Title = {Different ways to write digital audio effects programs},
	Pages = {188--91}, 
	Year = {1998},
        Address = {Barcelona, Spain}, 
        Month = {Nov. 19-21,}}

%example of reference to a technical report
@techreport{Askenfelt:1976:automatic:transcription,
	Author = {A. Askenfelt},
	Title = {Automatic notation of played music (status report)},
	Institution = {{STL-QPSR, Vol. 1, pp. 1--11}},
	Year = {1976}}

%example of reference to a master thesis
@mastersthesis{Egozy:1995:MIT:features:gesture,
	Author = {E.~B. Egozy}, 
	title = {Deriving musical control features from a real-time timbre analysis of the clarinet},
	School = {Massachusetts Institute of Technology}, 
	Year = {1995}}

%example of reference to a PhD thesis
@phdthesis{Dutilleux:1991,
	Author = {P. Dutilleux},
	School = {University of Aix-Marseille II},
	Title = {Vers la machine \`a sculpter le son, modification en temps-r\'eel des caract\'eristiques fr\'equentielles et temporelles des sons},
	Year = {1991}}



@Conference{Neidhardt2019ICSAbrirs,
  author    = {Neidhardt, A.},
  booktitle = {5th Int. Conference on Spatial Audio, Ilmenau, Germany},
  title     = {Data set: {BRIRs} for position-dynamic binaural synthesis measured in two rooms},
  year      = {2019},
  doi       = {10.22032/dbt.39972},
}


@TechReport{Neidhardt2023BRIRset2m,
  author      = {Neidhardt, Annika},
  institution = {Technische Universität Ilmenau},
  title       = {Data set of measured room impulse responses: {BRIRs, RIRs and SRIRs} for position-dynamic binaural auralization in two rooms},
  year        = {2023},
  doi         = {10.5281/zenodo.7838178},
  school      = {Data set (1.0), Zenodo},
  url         = {zenodo.org/record/7838178},
}


@Conference{NeidhardtDataset2023,
  author    = {A. Neidhardt},
  booktitle = {154th AES Convention, Espoo/Helsinki, Finland},
  title     = {Data set and physical analysis: {BRIRs and SRIRs} for walking toward, past and behind virtual loudspeakers in two rooms},
  year      = {2023},
}


@Conference{NEIDHARDT:POAIAM:2018,
  author    = {A. Neidhardt  and A. Ignatious-Tommy, and  A.~D. Pereppadan},
  title     = {Plausibility of an Interactive Approaching Motion towards a Virtual Sound Source Based on Simplified {BRIR} Sets},
  booktitle = {144th AES Convention, Milan, Italy},
  year      = {2018},
  month     = {},
}

@Conference{Jot2016,
  author    = {J.-M. Jotand K. S. Lee},
  title     = {Augmented Reality Headphone Environment Rendering},
  booktitle = {AES Int. Conf. on Audio for Virtual \& Augmented Reality},
  year      = {2016},
  address   = {Los Angeles, CA, USA, 2016},
  month     = {Sep},
}

@Conference{Poerschi2012,
  author    = {C. P{\"o}rschmann and A. Zebisch},
  title     = {Psychoacoustic investigations on synthetically created diffuse reverberation},
  booktitle = {27th Tonmeistertagung - VDT Int. Convention, Cologne, Germany},
  year      = {2012},
  pages     = {539--550},
  address   = {Cologne, Germany, 2012},
}


@Conference{NEIDHARDT:POAIAMSR:2022,
  author = {A. Neidhardt and S. Kamandi},
  title  = {Plausibility of an approaching motion towards a virtual sound source {II: I}n a reverberant seminar room},
  booktitle   = {152nd AES Convention, The Hague, The Netherlands},
  year   = {2022},
}

@Conference{Neidhardt2021Daga,
  author    = {A. Neidhardt and C. Schneiderwind},
  booktitle = {47th Annual Conference on Acoustics (DAGA), Vienna, Austria.},
  title     = {The influence of the {DRR} on audiovisual coherence of a real loudspeaker playing virtually over headphones},
  year      = {2021},
}


@article{NeidhardtReview2022,
 author               = {A. Neidhardt and C. Schneiderwind and F. Klein},
 journal              = {Trends in Hearing},
 title                = {Perceptual matching of room acoustics for auditory augmented reality in small rooms - literature review and theoretical framework},
 year                 = {2022},
 number               = {},
 month                = jan,
 pages                = {},
 volume               = {},
}

@article{NeidhardtZerlik,
  author = {A. Neidhardt and A.~M. Zerlik},
  title  = {The availability of a real hidden reference affects the plausibility of position-dynamic auditory {AR}},
  journal   = {Frontiers in VR},
  year   = {2021},
  doi    = {10.3389/frvir.2021.678875},
}

@Conference{SchneiderwindNeidhardt2022,
  author    = {C. Schneiderwind and A. Neidhardt},
  booktitle = {152nd AES Convention, paper 10604, The Hague, The Netherlands / Online},
  title     = {Discriminability of concurrent virtual and real sound sources in an augmented audio scenario},
  year      = {2022},
}

@Conference{NEIDHARDT:FPTFDBSA:2017,
 author               = {A. Neidhardt and F. Klein and N. Knoop and T. K\"ollmer},
 booktitle            = {eBrief 24, 142nd AES Convention, Berlin, Germany},
 journal              = {Unknown Journal},
 title                = {Flexible python tool for dynamic binaural synthesis applications},
 year                 = {2017},
}

@Article{Satongar2015,
  author    = {D. Satongar and C. Pike and Y.~W. Lam and A. I. Tew},
  title     = {The influence of headphones on the localization of external loudspeaker sources},
  journal   = {J. Audio Eng. Soc.},
  year      = {2015},
  volume    = {63},
  number    = {10},
  pages     = {799--810},
  month     = oct,
  doi       = {10.17743/jaes.2015.0072},
}





@INPROCEEDINGS{SchneiderwindMaike,
  author={C. Schneiderwind and M. Richter and N. Merten and A.  Neidhardt.},
  booktitle={2023 Immersive and 3D Audio: from Architecture to Automotive (I3DA)}, 
  title={Effects of Modified Late Reverberation on Audio-Visual Plausibility and Externalization in {AR}}, 
  year={2023},
  volume={},
  number={},
  pages={1-9},
  keywords={Tail;Speech enhancement;Length measurement;Market research;Fatigue;Acoustic measurements;Time measurement;Augmented Reality;Binaural Synthesis;Late Reverberation;Room Acoustics Modification;Externalization;Audio-Visual Plausibility},
  doi={10.1109/I3DA57090.2023.10289186}}

@inproceedings{SchneiderwindDaga2024,
    author = {C. Schneiderwind and L. Treybig},
    title = {Late Reverberation Synthesis in Small Rooms Considering Modal Properties},
    booktitle = {50th Annual Conference on Acoustics (DAGA), Hannover, Germany.},
    year = 2024
}

@article{antoni2010orthogonal,
  title={Orthogonal-like fractional-octave-band filters},
  author={J. Antoni},
  journal={The Journal of the Acoustical Society of America},
  volume={127},
  number={2},
  pages={884--895},
  year={2010},
  publisher={AIP Publishing}
}

@article{das2022modal,
  title={Modal Estimation on a Warped Frequency Axis for Linear System Modeling},
  author={O. Das and J.~S. Abel},
  journal={arXiv preprint arXiv:2202.11192},
  year={2022}
}

@inproceedings{kereliuk2018modal,
  title={Modal analysis of room impulse responses using subband ESPRIT},
  author={C. Kereliuk and W. Herman and R. Wedelich and D.~J. Gillespie},
  booktitle={Proceedings of the International Conference on Digital Audio Effects},
  year={2018}
}



@inproceedings{stade2016perceptual,
  title={Perceptual evaluation of synthetic late binaural reverberation based on a parametric model},
  author={P. Stade and J.~M. Arend},
  booktitle={Audio Engineering Society Conference: 2016 AES International Conference on Headphone Technology},
  year={2016},
  organization={Audio Engineering Society}
}

@article{Tervo2013,
author = {S. Tervo and J. P\"atynen and A. Kuusinen and T. Lokki},
year = {2013},
pages = {16-27},
title = {Spatial Decomposition Method for Room Impulse Responses},
volume = {61},
number = {1/2},
journal = {Journal of the Audio Engineering Society},
url     = {http://www.aes.org/e-lib/browse.cfm?elib=16664}
}


@book{morse1986theoretical,
  title={Theoretical acoustics},
  author={P.~M. Morse and K.~U. Ingard},
  year={1986},
  publisher={Princeton University Press}
}


@article{10.1121/1.414868,
    author = {M.~R. Schroeder},
    title = "{The ‘‘Schroeder frequency’’ revisited}",
    journal = {The Journal of the Acoustical Society of America},
    volume = {99},
    number = {5},
    pages = {3240-3241},
    year = {1996},
    month = {05},
    abstract = "{It is noted that the cross‐over frequency that marks the transition from individual resonances of a multimode system to overlapping normal modes, when expressed as a cross‐over wavelength, equals—within a numerical constant—the diffuse‐field distance in both three‐ and two‐dimensional resonators.}",
    issn = {0001-4966},
    doi = {10.1121/1.414868},
    url = {https://doi.org/10.1121/1.414868},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/99/5/3240/12187471/3240\_1\_online.pdf},
}


@conference{Werner2016,
  author={S. Werner and F. Klein and T. Mayenfels and K. Brandenburg},
  booktitle={2016 8th Int. Conf. on Quality of Multimedia Experience (QoMEX)}, 
  title={A summary on acoustic room divergence and its effect on externalization of auditory events}, 
  year={2016},
  volume={},
  number={},
  pages={1-6},
  keywords={Loudspeakers;Headphones;Acoustics;Visualization;Ear;Context;Training;binaural;perception;localization;externalization;context;quality},
  doi={10.1109/QoMEX.2016.7498973}}


@phdthesis{Gospodarek2024,
    author = {M. Gospodarek},
    title = {Acoustic and perceptual factors affecting plausibility in sound design for audio augmented reality experiences},
    school = {New York University, NY, USA},
    year = {2024}
}

@conference{Muelleder2023, 
author={Mülleder, A. and Romanov, M. and Meyer-Kahlen, N. and Zotter, F.}, 
booktitle={AES International Conference, Huddersfield, UK}, 
title={Do-it-yourself headphones and development platform for augmented-reality audio}, 
year={2023}, 
month={aug}
} 

@misc{femalespeechstimulus,
    key = {},
    author = {Univ. of York},
    title = {Anechoic data: openair},
    note = {{https://www.openair.hosted.york.ac.uk/?page id=310}},
    year = {2023}
}

@misc{drumloop,
    author = {Dear Reality},
    title = {{dearVR UNITY}},
    note = {accessed: 6/6/2023,
    {https://www.dear-reality.com/products/dearvr-unity}},
    year = {2023}
}

@misc{sherlock,
    author = {J. Taylor},
    title = {Sherlock {Holmes: Rediscovered Railway Mysteries - An Inscrutable Masquerade}},
    note = {accessed: 01/09/2024, {https://archive.org/details/11\_20240207}},
    
}

@misc{sax,
    key = {},
    note = {accessed: ...},
    url = {}
}


@article{Teret2017,
    author = {Teret, E. and Pastore, M. T. and Braasch, J.},
    title = {The influence of signal type on perceived reverberance},
    journal = {The Journal of the Acoustical Society of America},
    volume = {141},
    number = {3},
    pages = {1675-1682},
    year = {2017},
    month = {03},
    abstract = {Currently, architectural room acoustic metrics make no real distinction between a room impulse response and the auditory system's internal representation of a room. These metrics are generally based on impulse responses, and indirectly assume that the internal representation of the acoustic features of a room is independent of the sound source. However, while a room can be approximated as a linear, time-invariant system, auditory processing is highly non-linear and varies a great deal over time in response to different acoustic inputs. Listeners were presented with various signals (clicks, long-duration noise, music, and speech) convolved with impulse responses consisting of Gaussian noises with different rates of exponential decay. Listeners were asked to adjust the reverberation time of one of the signals to match the other. Analyses of the data show that the source signal has a significant influence on perceived reverberance. Also, listeners were less accurate when matching reverberation times between different signals than they were with identical signals, suggesting that predicting subjective measures of reverberance from room impulse responses faces severe limitations that cannot be neglected. Results further suggest that the auditory system does not have a well-developed temporal representation of the diffuse reverb tail.},
    issn = {0001-4966},
    doi = {10.1121/1.4977748},
    url = {https://doi.org/10.1121/1.4977748},
    eprint = {https://pubs.aip.org/asa/jasa/article-pdf/141/3/1675/15322685/1675\_1\_online.pdf},
}

@conference{godin2019aesthetic,
		title = {Aesthetic Modification of Room Impulse Responses for Interactive Auralization},
		author = {Godin, K. and Gamper, H. and Raghuvanshi, N.},
		booktitle = {AES Int. Conference on Immersive and Interactive Audio.},
		month = {Mar},
		year = {2019},
		url = {https://www.aes.org/e-lib/browse.cfm?elib=20444}
		}


@Article{Osses2017,
  author    = {O. Vecchi, A. and Kohlrausch, A. and Lachenmayr, W. and Mommertz, E.},
  title     = {Predicting the perceived reverberation in different room acoustic environments using a binaural auditory model},
  journal   = {J.~Acoust. Soc. Am.},
  year      = {2017},
  volume    = {141},
  number    = {4},
  pages     = {EL381--EL387},
  doi       = {10.1121/1.4979853},
}


@article {Teng2017,
	author = {Teng, S. and Sommer, V. R. and Pantazis, D. and Oliva, A.},
	title = {Hearing Scenes: A Neuromagnetic Signature of Auditory Source and Reverberant Space Separation},
	volume = {4},
	number = {1},
	elocation-id = {ENEURO.0007-17.2017},
	year = {2017},
	doi = {10.1523/ENEURO.0007-17.2017},
	publisher = {Society for Neuroscience},
	abstract = {Perceiving the geometry of surrounding space is a multisensory process, crucial to contextualizing object perception and guiding navigation behavior. Humans can make judgments about surrounding spaces from reverberation cues, caused by sounds reflecting off multiple interior surfaces. However, it remains unclear how the brain represents reverberant spaces separately from sound sources. Here, we report separable neural signatures of auditory space and source perception during magnetoencephalography (MEG) recording as subjects listened to brief sounds convolved with monaural room impulse responses (RIRs). The decoding signature of sound sources began at 57 ms after stimulus onset and peaked at 130 ms, while space decoding started at 138 ms and peaked at 386 ms. Importantly, these neuromagnetic responses were readily dissociable in form and time: while sound source decoding exhibited an early and transient response, the neural signature of space was sustained and independent of the original source that produced it. The reverberant space response was robust to variations in sound source, and vice versa, indicating a generalized response not tied to specific source-space combinations. These results provide the first neuromagnetic evidence for robust, dissociable auditory source and reverberant space representations in the human brain and reveal the temporal dynamics of how auditory scene analysis extracts percepts from complex naturalistic auditory signals.},
	URL = {https://www.eneuro.org/content/4/1/ENEURO.0007-17.2017},
	journal = {eNeuro}
}

@article{eaton2016estimation,
  title={Estimation of room acoustic parameters: The ACE challenge},
  author={Eaton, James and Gaubitch, Nikolay D and Moore, Alastair H and Naylor, Patrick A},
  journal={IEEE/ACM Transactions on Audio, Speech, and Language Processing},
  volume={24},
  number={10},
  pages={1681--1693},
  year={2016},
  publisher={IEEE}
}


@article{Leonard2013,
    author = {Leonard, Brett and King, Richard L. and Sikora, Grzegorz},
    title = {Interaction between critical listening environment acoustics and listener reverberation preference},
    journal = {Proceedings of Meetings on Acoustics},
    volume = {19},
    number = {1},
    pages = {015037},
    year = {2013},
    month = {05},
    abstract = {Reverberation is a central effect in many modern music productions.  In the case of classical music, it may even be the only effect used.  There is, however, minimal literature concerning the interaction between reverberation preference and the listening environment used during critical mixing tasks.  In order to explore this critical interaction, a group of highly trained subjects are tasked with adding reverberation to dry, premixed stereo program material in two different acoustic environments: a recording studio control room and a highly reflective room.  The control room is representative of most studios, with an RT of approximately 200 ms.  The reflective environment more closely approximates an untreated residential room, with an RT of over 350 ms, with a marked increase in lateral energy.  Somewhat predictably, the mean preferred reverberation level is higher in a less reverberant environment, but the distributions of reverberation level preference are shown to be narrower for the more reflective mixing environment.  The time it takes for subjects to reach a decision is similar in both environments, but the reflective environment seems to suggest a longer period of adaptation at the beginning of each trial set.},
    issn = {1939-800X},
    doi = {10.1121/1.4799258},
    url = {https://doi.org/10.1121/1.4799258},
    eprint = {https://pubs.aip.org/asa/poma/article-pdf/doi/10.1121/1.4799258/18241800/pma.v19.i1.015037\_1.online.pdf},
}


@article{Neidhardt2025dirIndir,
    author = {A. Neidhardt},
    title = {Effect of impaired early reflection patterns on plausibility and similarity of position-dynamic binaural AR audio},
    journal = {Submitted},
    year = {2025}
}